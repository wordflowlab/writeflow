/**
 * WriteFlow AI æœåŠ¡
 * ä¸“ä¸ºå†™ä½œåœºæ™¯ä¼˜åŒ–çš„ AI æœåŠ¡
 */

import { getGlobalConfig, ModelProfile } from '../../utils/config.js'
import { getModelManager } from '../models/ModelManager.js'
import { getModelCapabilities } from '../models/modelCapabilities.js'
import { logError } from '../../utils/log.js'
import { 
  getTool, 
  getToolOrchestrator, 
  getPermissionManager,
  getAvailableTools,
  executeToolQuick,
  ToolExecutionStatus,
  type ToolExecutionResult,
  type WriteFlowTool
} from '../../tools/index.js'
import { formatContent, toolFormatter } from '../../utils/SmartFormatter.js'
import { format } from '../../utils/colorScheme.js'
import { analyzeContent } from '../../utils/contentAnalyzer.js'
import { AgentContext } from '../../types/agent.js'
import { ToolUseContext } from '../../Tool.js'
import { getResponseStateManager } from '../streaming/ResponseStateManager.js'
import { getProviderAdapter } from './providers/index.js'
import { emitReminderEvent } from '../SystemReminderService.js'
import { startStreamingProgress, stopStreamingProgress } from '../streaming/ProgressIndicator.js'
import { getOutputFormatter } from '../../ui/utils/outputFormatter.js'
import { parseAIResponse, parseStreamingChunk, type ParsedResponse } from './ResponseParser.js'
import type { 
  ContentBlock, 
  LongContentBlock 
} from '../../types/UIMessage.js'
import { 
  createTextBlock, 
  createLongContentBlock
} from '../../types/UIMessage.js'
import type { 
  CollapsibleContentType, 
  ContentAnalysis
} from '../../types/CollapsibleContent.js'
import { 
  AUTO_COLLAPSE_THRESHOLDS,
  CONTENT_TYPE_PATTERNS 
} from '../../types/CollapsibleContent.js'
import { generateOptimizedSystemPrompt } from '../../tools/SystemPromptOptimizer.js'
import { addCostEntry } from '../CostTracker.js'
import { getContextManager, estimateTokens, ContextEntry } from '../ContextManager.js'

export interface AIRequest {
  prompt: string
  systemPrompt?: string
  model?: string
  maxTokens?: number
  temperature?: number
  stream?: boolean
  onToken?: (chunk: string) => void
  allowedTools?: string[]
  enableToolCalls?: boolean
  // æ™ºèƒ½åˆ†æç›¸å…³é€‰é¡¹
  enableSmartAnalysis?: boolean
  taskContext?: string
  autoGenerateSystemPrompt?: boolean
}

export interface AIResponse {
  content: string
  contentBlocks?: ContentBlock[]  // æ–°å¢ï¼šç»“æ„åŒ–å†…å®¹å—
  usage: {
    inputTokens: number
    outputTokens: number
  }
  cost: number
  duration: number
  model: string
  toolCalls?: ToolCall[]
  hasToolInteraction?: boolean
  streamingStats?: {
    duration: number
    tokenCount: number
    tokensPerSecond: number
    startTime: number
    endTime: number
  }
}

export interface ToolCall {
  toolName: string
  parameters: any
  callId: string
}

export interface AIToolExecutionResult {
  toolName: string
  callId: string
  result: string
  success: boolean
  error?: string
}

/**
 * WriteFlow AI æœåŠ¡ç±» - é›†æˆå¢å¼ºå·¥å…·ç³»ç»Ÿ
 */
export class WriteFlowAIService {
  private modelManager = getModelManager()
  private toolOrchestrator = getToolOrchestrator()
  private permissionManager = getPermissionManager()
  private providerAdapter = getProviderAdapter(undefined)
  private contextManager = getContextManager()
  
  /**
   * å¤„ç† AI è¯·æ±‚ï¼ˆæ”¯æŒæµå¼å’Œéæµå¼ï¼‰
   */
  async processRequest(request: AIRequest): Promise<AIResponse> {
    // é¢„å¤„ç†è¯·æ±‚ï¼šæ™ºèƒ½åˆ†æå’Œç³»ç»Ÿæç¤ºè¯å¢å¼º
    const enhancedRequest = await this.enhanceRequest(request)
    
    // å¦‚æœè¯·æ±‚æµå¼å¤„ç†ï¼Œå§”æ‰˜ç»™æµå¼æœåŠ¡
    if (enhancedRequest.stream) {
      return this.processStreamingRequest(enhancedRequest)
    }
    
    return this.processNonStreamingRequest(enhancedRequest)
  }

  /**
   * å¢å¼ºè¯·æ±‚ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶å¯ç”¨æ™ºèƒ½åˆ†æåŠŸèƒ½
   */
  private async enhanceRequest(request: AIRequest): Promise<AIRequest> {
    const enhanced = { ...request }
    
    // è‡ªåŠ¨æ£€æµ‹æ˜¯å¦éœ€è¦æ™ºèƒ½åˆ†æ
    const needsSmartAnalysis = this.detectSmartAnalysisNeed(request.prompt)
    
    if (needsSmartAnalysis || request.enableSmartAnalysis) {
      // å¯ç”¨å·¥å…·è°ƒç”¨
      enhanced.enableToolCalls = true
      enhanced.allowedTools = enhanced.allowedTools || [
        'Read', 'Grep', 'Glob', 'Bash', 
        'todo_write', 'todo_read'
      ]
      
      // è®¾ç½®ä»»åŠ¡ä¸Šä¸‹æ–‡
      enhanced.taskContext = enhanced.taskContext || this.extractTaskContext(request.prompt)
    }
    
    // è‡ªåŠ¨ç”Ÿæˆæˆ–å¢å¼ºç³»ç»Ÿæç¤ºè¯
    if (enhanced.autoGenerateSystemPrompt !== false) {
      enhanced.systemPrompt = await this.generateEnhancedSystemPrompt(enhanced)
    }
    
    return enhanced
  }

  /**
   * æ£€æµ‹æ˜¯å¦éœ€è¦æ™ºèƒ½åˆ†æ
   */
  private detectSmartAnalysisNeed(prompt: string): boolean {
    const analysisKeywords = [
      'åˆ†æ', 'é¡¹ç›®', 'æ€»ç»“', 'ç†è§£', 'æŸ¥çœ‹', 'æ£€æŸ¥', 'æœç´¢', 'æ¢ç´¢',
      'analyze', 'project', 'summary', 'understand', 'explore', 'search'
    ]
    
    const lowerPrompt = prompt.toLowerCase()
    return analysisKeywords.some(keyword => 
      lowerPrompt.includes(keyword) || 
      lowerPrompt.includes(keyword.toLowerCase())
    )
  }

  /**
   * ä»æç¤ºè¯ä¸­æå–ä»»åŠ¡ä¸Šä¸‹æ–‡
   */
  private extractTaskContext(prompt: string): string {
    // ç®€å•çš„ä¸Šä¸‹æ–‡æå–é€»è¾‘
    if (prompt.includes('é¡¹ç›®') || prompt.includes('project')) {
      return 'é¡¹ç›®åˆ†æå’Œç»“æ„ç†è§£'
    }
    if (prompt.includes('ä»£ç ') || prompt.includes('code')) {
      return 'ä»£ç åˆ†æå’Œç†è§£'
    }
    if (prompt.includes('æ–‡ä»¶') || prompt.includes('file')) {
      return 'æ–‡ä»¶åˆ†æå’Œå¤„ç†'
    }
    return 'æ™ºèƒ½åˆ†æä»»åŠ¡'
  }

  /**
   * ç”Ÿæˆå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
   */
  private async generateEnhancedSystemPrompt(request: AIRequest): Promise<string> {
    try {
      const optimizedPrompt = await generateOptimizedSystemPrompt({
        taskContext: request.taskContext,
        safeMode: false,
        compact: false
      })
      
      // å¦‚æœç”¨æˆ·æä¾›äº†è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Œå°†å…¶ä¸ä¼˜åŒ–æç¤ºè¯åˆå¹¶
      if (request.systemPrompt) {
        return `${optimizedPrompt}\n\n## ç”¨æˆ·è‡ªå®šä¹‰æŒ‡ä»¤\n${request.systemPrompt}`
      }
      
      return optimizedPrompt
    } catch (error) {
      console.warn('ç”Ÿæˆä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯:', error)
      return request.systemPrompt || 'ä½ æ˜¯ WriteFlow AI å†™ä½œåŠ©æ‰‹ï¼Œè¯·å¸®åŠ©ç”¨æˆ·å®Œæˆå„ç§å†™ä½œå’Œåˆ†æä»»åŠ¡ã€‚'
    }
  }

  /**
   * æ˜¾ç¤ºå·¥å…·æ‰§è¡Œè¿‡ç¨‹çš„è¯¦ç»†åé¦ˆï¼Œä½¿ç”¨æ™ºèƒ½æ ¼å¼åŒ–å™¨
   */
  private displayToolExecution(toolCall: any): ContentBlock | null {
    const { name: toolName, arguments: argsStr } = toolCall.function
    
    try {
      const args = JSON.parse(argsStr)
      
      // ğŸ”§ æ ‡å‡†åŒ–å‚æ•°ä»¥æ”¯æŒä¸åŒçš„å‚æ•°å‘½å
      const normalizedArgs = this.normalizeToolParams(toolName, args)
      
      // ç®€åŒ–çš„æ§åˆ¶å°è¾“å‡º - åªæ˜¾ç¤ºå…³é”®ä¿¡æ¯
      const briefMessage = this.getBriefToolMessage(toolName, normalizedArgs)
      
      // æ„å»ºè¯¦ç»†å†…å®¹ç”¨äºå±•å¼€
      const detailedContent = this.formatDetailedToolExecution(toolName, normalizedArgs, 'æ‰§è¡Œä¸­...')
      
      // æ§åˆ¶å°æ˜¾ç¤ºç®€æ´ä¿¡æ¯å’Œå±•å¼€æç¤º
      console.log(`${briefMessage} ${format.dim('(Ctrl+R to expand)')}`)
      
      // åˆ›å»ºå¯æŠ˜å çš„å·¥å…·æ‰§è¡Œå—
      const contentId = `tool-exec-${toolName.toLowerCase()}-${Date.now()}`
      return createLongContentBlock(
        detailedContent,
        'tool-execution',
        briefMessage,
        { 
          collapsed: true, // é»˜è®¤æŠ˜å ï¼Œæ˜¾ç¤ºç®€æ´ä¿¡æ¯
          maxLines: 1,
          id: contentId
        },
        {
          toolName,
          contentType: 'tool-execution',
          estimatedLines: detailedContent.split('\n').length,
          hasLongContent: true
        }
      )
      
    } catch (error) {
      const simpleMessage = format.tool(toolName, 'æ‰§è¡Œä¸­')
      console.log(`${simpleMessage} ${format.dim('(parsing error)')}`)
      
      // å³ä½¿è§£æå¤±è´¥ä¹Ÿåˆ›å»ºåŸºæœ¬çš„å†…å®¹å—
      return createTextBlock(
        simpleMessage,
        {
          id: `tool-${Date.now()}`,
          collapsed: false,
          autoCollapse: false,
          maxLines: 3
        },
        {
          estimatedLines: 1,
          hasLongContent: false,
          contentType: 'tool-execution',
          toolName
        }
      )
    }
  }

  /**
   * æ ¼å¼åŒ–è¯¦ç»†çš„å·¥å…·æ‰§è¡Œä¿¡æ¯
   */
  private formatDetailedToolExecution(toolName: string, args: any, status: string): string {
    const lines = [`ğŸ”§ ${toolName} å·¥å…·æ‰§è¡Œè¯¦ç»†ä¿¡æ¯`, '']
    
    // æ·»åŠ å‚æ•°ä¿¡æ¯
    lines.push('å‚æ•°:')
    for (const [key, value] of Object.entries(args)) {
      const displayValue = typeof value === 'string' && value.length > 100 
        ? value.slice(0, 100) + '...' 
        : JSON.stringify(value)
      lines.push(`  ${key}: ${displayValue}`)
    }
    
    lines.push('')
    lines.push(`çŠ¶æ€: ${status}`)
    
    return lines.join('\n')
  }

  /**
   * ç”Ÿæˆç®€åŒ–çš„å·¥å…·æ‰§è¡Œæ¶ˆæ¯ - åªæ˜¾ç¤ºæœ€å…³é”®çš„ä¿¡æ¯
   */
  private getBriefToolMessage(toolName: string, args: any): string {
    switch (toolName) {
      case 'Read':
        const fileName = this.getFileName(args.file_path || 'æœªçŸ¥æ–‡ä»¶')
        return format.info(`ğŸ“– è¯»å– ${fileName}`)
      case 'Grep':
        const pattern = args.pattern || 'æœªçŸ¥æ¨¡å¼'
        return format.info(`ğŸ” æœç´¢ "${pattern}"`)
      case 'Glob':
        const globPattern = args.pattern || 'æœªçŸ¥æ¨¡å¼'
        return format.info(`ğŸ“ æŸ¥æ‰¾ ${globPattern}`)
      case 'Bash':
        const cmd = this.getSimpleCommand(args.command || 'æœªçŸ¥å‘½ä»¤')
        return format.info(`âš¡ æ‰§è¡Œ ${cmd}`)
      case 'Write':
        const writeFile = this.getFileName(args.file_path || 'æœªçŸ¥æ–‡ä»¶')
        return format.info(`âœï¸ å†™å…¥ ${writeFile}`)
      case 'Edit':
        const editFile = this.getFileName(args.file_path || 'æœªçŸ¥æ–‡ä»¶')
        return format.info(`âœ‚ï¸ ç¼–è¾‘ ${editFile}`)
      default:
        return format.info(`ğŸ”§ ${toolName}`)
    }
  }
  
  /**
   * ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶å
   */
  private getFileName(filePath: string): string {
    const parts = filePath.split('/')
    return parts[parts.length - 1] || filePath
  }
  
  /**
   * ç®€åŒ–å‘½ä»¤æ˜¾ç¤º
   */
  private getSimpleCommand(command: string): string {
    if (command.length > 30) {
      return command.split(' ')[0] + '...'
    }
    return command
  }
  
  /**
   * ç”Ÿæˆç®€åŒ–çš„å·¥å…·ç»“æœæ¶ˆæ¯
   */
  private getBriefResultMessage(toolName: string, status: string, result: string): string {
    const lines = result.split('\n').length
    const chars = result.length
    
    let statusIcon = ''
    let statusColor = format.success
    
    switch (status) {
      case 'success':
        statusIcon = 'âœ…'
        statusColor = format.success
        break
      case 'error':
        statusIcon = 'âŒ'
        statusColor = format.error
        break
      default:
        statusIcon = 'ğŸ”§'
        statusColor = format.info
    }
    
    // æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆä¸åŒçš„ç»“æœæ‘˜è¦
    switch (toolName) {
      case 'Read':
        if (status === 'success') {
          return statusColor(`${statusIcon} è¯»å–å®Œæˆ (${lines} è¡Œ)`)
        } else {
          return statusColor(`${statusIcon} è¯»å–å¤±è´¥`)
        }
      case 'Grep':
        if (status === 'success') {
          const matches = lines - 1 // é€šå¸¸ç¬¬ä¸€è¡Œæ˜¯æ–‡ä»¶è·¯å¾„
          return statusColor(`${statusIcon} æ‰¾åˆ° ${matches} ä¸ªåŒ¹é…`)
        } else {
          return statusColor(`${statusIcon} æœç´¢å¤±è´¥`)
        }
      case 'Glob':
        if (status === 'success') {
          return statusColor(`${statusIcon} æ‰¾åˆ° ${lines} ä¸ªæ–‡ä»¶`)
        } else {
          return statusColor(`${statusIcon} æŸ¥æ‰¾å¤±è´¥`)
        }
      case 'Bash':
        if (status === 'success') {
          return statusColor(`${statusIcon} å‘½ä»¤æ‰§è¡Œå®Œæˆ`)
        } else {
          return statusColor(`${statusIcon} å‘½ä»¤æ‰§è¡Œå¤±è´¥`)
        }
      case 'Write':
      case 'Edit':
        if (status === 'success') {
          return statusColor(`${statusIcon} æ–‡ä»¶ä¿å­˜æˆåŠŸ`)
        } else {
          return statusColor(`${statusIcon} æ–‡ä»¶ä¿å­˜å¤±è´¥`)
        }
      default:
        if (status === 'success') {
          return statusColor(`${statusIcon} ${toolName} å®Œæˆ`)
        } else {
          return statusColor(`${statusIcon} ${toolName} å¤±è´¥`)
        }
    }
  }

  /**
   * æå–å·¥å…·çš„å…³é”®å‚æ•°ç”¨äºæ˜¾ç¤º
   */
  private extractKeyParams(toolName: string, args: any): [string, string][] {
    const params: [string, string][] = []
    
    switch (toolName) {
      case 'Read':
        if (args.file_path) params.push(['æ–‡ä»¶', format.path(args.file_path)])
        break
      case 'Grep':
        if (args.pattern) params.push(['æ¨¡å¼', args.pattern])
        if (args.path) params.push(['è·¯å¾„', args.path])
        break
      case 'Glob':
        if (args.pattern) params.push(['æ¨¡å¼', args.pattern])
        if (args.path) params.push(['è·¯å¾„', args.path])
        break
      case 'Bash':
        if (args.command) {
          const cmd = args.command.length > 50 ? args.command.slice(0, 50) + '...' : args.command
          params.push(['å‘½ä»¤', cmd])
        }
        break
      case 'Write':
      case 'Edit':
        if (args.file_path) params.push(['æ–‡ä»¶', format.path(args.file_path)])
        break
      default:
        // å¯¹äºå…¶ä»–å·¥å…·ï¼Œæ˜¾ç¤ºå‰2ä¸ªå‚æ•°
        const entries = Object.entries(args).slice(0, 2)
        entries.forEach(([key, value]) => {
          const strValue = String(value)
          const displayValue = strValue.length > 50 ? strValue.slice(0, 50) + '...' : strValue
          params.push([key, displayValue])
        })
    }
    
    return params
  }

  /**
   * åˆ›å»ºå·¥å…·æ‰§è¡Œç»“æœçš„å†…å®¹å— - ä½¿ç”¨æ™ºèƒ½æ ¼å¼åŒ–å™¨
   */
  private createToolResultBlock(
    toolName: string, 
    result: string, 
    success: boolean,
    callId?: string
  ): ContentBlock {
    const status = success ? 'success' : 'error'
    
    // ç®€åŒ–çš„ç»“æœè¾“å‡º
    const briefResult = this.getBriefResultMessage(toolName, status, result)
    
    // æ ¼å¼åŒ–è¯¦ç»†ç»“æœ
    const detailedResult = this.formatDetailedToolResult(toolName, result, success)
    
    // æ§åˆ¶å°æ˜¾ç¤ºç®€æ´ä¿¡æ¯å’Œå±•å¼€æç¤º
    const resultLines = result.split('\n').length
    console.log(`${briefResult} ${format.dim(`(${resultLines} lines, Ctrl+R to expand)`)}`)
    
    // ä½¿ç”¨å†…å®¹åˆ†æå™¨åˆ†æç»“æœ
    const analysis = analyzeContent(result)
    
    // æ€»æ˜¯åˆ›å»ºå¯æŠ˜å çš„é•¿å†…å®¹å—ï¼Œè®©ç”¨æˆ·å¯ä»¥é€‰æ‹©å±•å¼€
    const resultId = `tool-result-${toolName.toLowerCase()}-${Date.now()}`
    return createLongContentBlock(
      detailedResult,
      analysis.contentType,
      briefResult,
      {
        collapsed: true, // é»˜è®¤æŠ˜å ï¼Œæ˜¾ç¤ºç®€æ´ä¿¡æ¯
        maxLines: analysis.shouldCollapse ? 15 : 5,
        id: resultId
      },
      {
        toolName,
        contentType: analysis.contentType,
        estimatedLines: analysis.estimatedLines,
        hasLongContent: true
      }
    )
  }

  /**
   * æ ¼å¼åŒ–è¯¦ç»†çš„å·¥å…·æ‰§è¡Œç»“æœ
   */
  private formatDetailedToolResult(toolName: string, result: string, success: boolean): string {
    const lines = [`ğŸ”§ ${toolName} æ‰§è¡Œç»“æœ`, '']
    
    lines.push(`çŠ¶æ€: ${success ? 'âœ… æˆåŠŸ' : 'âŒ å¤±è´¥'}`)
    lines.push(`ç»“æœé•¿åº¦: ${result.length} å­—ç¬¦ï¼Œ${result.split('\n').length} è¡Œ`)
    lines.push('')
    lines.push('è¯¦ç»†å†…å®¹:')
    lines.push('â”€'.repeat(40))
    lines.push(result)
    lines.push('â”€'.repeat(40))
    
    return lines.join('\n')
  }


  /**
   * åˆ†æå†…å®¹å¹¶å†³å®šæ˜¯å¦éœ€è¦åˆ›å»ºå¯æŠ˜å å—
   */
  /**
   * æ£€æµ‹æ˜¯å¦ä¸ºåˆ›ä½œå†…å®¹ï¼ˆæ°¸è¿œä¸åº”è¯¥è¢«æŠ˜å ï¼‰
   */
  private isCreativeContent(content: string): boolean {
    const creativePatternsOrder = [
      CONTENT_TYPE_PATTERNS['creative-content'],
      CONTENT_TYPE_PATTERNS['creative-writing'], 
      CONTENT_TYPE_PATTERNS['article'],
      CONTENT_TYPE_PATTERNS['novel']
    ]
    
    return creativePatternsOrder.some(pattern => pattern.test(content))
  }

  private analyzeContentForCollapsible(content: string): ContentAnalysis {
    const lines = content.split('\n')
    const lineCount = lines.length
    const charCount = content.length
    const hasLongLines = lines.some(line => line.length > 120)
    const hasCodeBlocks = /```[\s\S]*?```/.test(content)
    
    // æ£€æµ‹å†…å®¹ç±»å‹
    let contentType: CollapsibleContentType = 'long-text'
    for (const [type, pattern] of Object.entries(CONTENT_TYPE_PATTERNS)) {
      if (pattern.test(content)) {
        contentType = type as CollapsibleContentType
        break
      }
    }
    
    // ä¼˜å…ˆæ£€æµ‹åˆ›ä½œå†…å®¹ - æ°¸è¿œä¸æŠ˜å 
    if (this.isCreativeContent(content)) {
      return {
        shouldAutoCollapse: false,  // åˆ›ä½œå†…å®¹æ°¸è¿œä¸æŠ˜å 
        estimatedLines: lineCount,
        contentType: 'creative-content',
        hasCodeBlocks,
        hasLongLines,
        complexity: lineCount > 50 ? 'complex' : lineCount > 20 ? 'medium' : 'simple'
      }
    }
    
    // åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨æŠ˜å 
    let shouldAutoCollapse = false
    switch (contentType) {
      case 'tool-execution':
        shouldAutoCollapse = lineCount > AUTO_COLLAPSE_THRESHOLDS.toolOutputLines
        break
      case 'code-block':
        shouldAutoCollapse = lineCount > AUTO_COLLAPSE_THRESHOLDS.codeBlockLines
        break
      case 'error-message':
        shouldAutoCollapse = lineCount > AUTO_COLLAPSE_THRESHOLDS.errorMessageLines
        break
      case 'creative-content':
      case 'creative-writing':
      case 'article':
      case 'novel':
        shouldAutoCollapse = false  // åˆ›ä½œå†…å®¹æ°¸è¿œä¸æŠ˜å 
        break
      default:
        shouldAutoCollapse = lineCount > AUTO_COLLAPSE_THRESHOLDS.lines || 
                           charCount > AUTO_COLLAPSE_THRESHOLDS.characters
    }
    
    // è®¡ç®—å¤æ‚åº¦
    let complexity: ContentAnalysis['complexity'] = 'simple'
    if (hasCodeBlocks || lineCount > 50) complexity = 'complex'
    else if (lineCount > 20 || hasLongLines) complexity = 'medium'
    
    return {
      shouldAutoCollapse,
      estimatedLines: lineCount,
      contentType,
      hasCodeBlocks,
      hasLongLines,
      complexity
    }
  }

  /**
   * å°†é•¿å†…å®¹è½¬æ¢ä¸ºå¯æŠ˜å çš„å†…å®¹å—
   */
  private createCollapsibleContentBlocks(content: string): ContentBlock[] {
    const analysis = this.analyzeContentForCollapsible(content)
    
    // å¦‚æœå†…å®¹ä¸éœ€è¦æŠ˜å ï¼Œè¿”å›æ™®é€šæ–‡æœ¬å—
    if (!analysis.shouldAutoCollapse) {
      return [createTextBlock(content)]
    }
    
    // åˆ›å»ºå¯æŠ˜å çš„é•¿å†…å®¹å—
    return [createLongContentBlock(
      content,
      analysis.contentType,
      undefined, // è®©ç»„ä»¶è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜
      {
        collapsed: analysis.shouldAutoCollapse,
        maxLines: AUTO_COLLAPSE_THRESHOLDS.lines,
        autoCollapse: true
      },
      {
        estimatedLines: analysis.estimatedLines,
        hasLongContent: true,
        contentType: analysis.contentType
      }
    )]
  }

  /**
   * è¿‡æ»¤ DeepSeek ç­‰æ¨¡å‹åœ¨æ–‡æœ¬ä¸­å†…è”æš´éœ²çš„å·¥å…·æ ‡è®°
   * æ¸…ç†å½¢å¦‚ <ï½œtoolâ–callsâ–beginï½œ> ... <ï½œtoolâ–callsâ–endï½œ> ä»¥åŠå•ä¸ª <ï½œtoolâ–...ï½œ>
   */
  private sanitizeLLMArtifacts(text: string | undefined): string {
    return this.providerAdapter.sanitizeText(text || '')
  }

  /**
   * ä»æ–‡æœ¬ä¸­æå– DeepSeek çš„å†…è”å·¥å…·è°ƒç”¨ï¼Œè¿”å›æ¸…ç†åçš„æ–‡æœ¬ä¸è§£æå‡ºçš„è°ƒç”¨
   */
  private extractInlineToolCalls(text: string) {
    return this.providerAdapter.extractInlineToolCalls(text)
  }
  
  /**
   * å¤„ç†æµå¼ AI è¯·æ±‚ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥å¤„ç†è€Œä¸ä¾èµ–å¤æ‚çš„ StreamingService
   */
  async processStreamingRequest(request: AIRequest): Promise<AIResponse> {
    const startTime = Date.now()
    
    try {
      // ç¦»çº¿æ¨¡å¼ä¸‹ç›´æ¥å›é€€åˆ°éæµå¼å¤„ç†
      if (process.env.WRITEFLOW_AI_OFFLINE === 'true') {
        return this.processNonStreamingRequest({ ...request, stream: false })
      }
      
      // ä»è¯·æ±‚æˆ–ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åç§°
      const modelName = request.model || process.env.AI_MODEL || this.getDefaultModelName()
      if (!modelName) {
        console.warn('æ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œå›é€€åˆ°éæµå¼å¤„ç†')
        return this.processNonStreamingRequest({ ...request, stream: false })
      }
      
      // æ ¹æ®æ¨¡å‹åç§°åˆ›å»ºä¸´æ—¶çš„æ¨¡å‹é…ç½®
      const modelProfile = this.createTempModelProfile(modelName)
      if (!modelProfile) {
        console.warn(`ä¸æ”¯æŒçš„æ¨¡å‹: ${modelName}ï¼Œå›é€€åˆ°éæµå¼å¤„ç†`)
        return this.processNonStreamingRequest({ ...request, stream: false })
      }
      
      // æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæµå¼
      const capabilities = getModelCapabilities(modelName)
      if (!capabilities.supportsStreaming) {
        console.warn(`æ¨¡å‹ ${modelName} ä¸æ”¯æŒæµå¼ï¼Œå›é€€åˆ°éæµå¼å¤„ç†`)
        return this.processNonStreamingRequest({ ...request, stream: false })
      }
      
      // ç›´æ¥è°ƒç”¨å¯¹åº”çš„ API è¿›è¡Œæµå¼å¤„ç†
      this.providerAdapter = getProviderAdapter(modelProfile.provider)
      switch (modelProfile.provider) {
        case 'deepseek':
          return await this.callDeepSeekAPI(modelProfile, request)
        case 'anthropic':
        case 'bigdream':
          return await this.callAnthropicAPI(modelProfile, request)
        case 'openai':
          return await this.callOpenAIAPI(modelProfile, request)
        case 'kimi':
          return await this.callKimiAPI(modelProfile, request)
        default:
          console.warn(`ä¸æ”¯æŒæµå¼çš„æä¾›å•†: ${modelProfile.provider}ï¼Œå›é€€åˆ°éæµå¼å¤„ç†`)
          return this.processNonStreamingRequest({ ...request, stream: false })
      }
      
    } catch (error) {
      logError('æµå¼ AI è¯·æ±‚å¤„ç†å¤±è´¥', error)
      
      // æ ‡è®°æµå¼å“åº”é”™è¯¯ï¼ˆå¦‚æœæœ‰æ´»è·ƒçš„æµå¼ä¼šè¯ï¼‰
      const responseManager = getResponseStateManager()
      const activeStats = responseManager.getActiveStreamingStats()
      if (activeStats.activeStreams > 0) {
        // æ‰¾åˆ°å¯èƒ½çš„æµå¼ä¼šè¯å¹¶æ ‡è®°é”™è¯¯
        console.warn(`å‘ç° ${activeStats.activeStreams} ä¸ªæ´»è·ƒæµå¼ä¼šè¯ï¼Œæ ‡è®°ä¸ºé”™è¯¯çŠ¶æ€`)
      }
      
      // å›é€€åˆ°éæµå¼å¤„ç†ï¼Œæ˜ç¡®è®¾ç½® stream: false é˜²æ­¢é€’å½’
      console.warn('æµå¼å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°éæµå¼å¤„ç†')
      return this.processNonStreamingRequest({ ...request, stream: false })
    }
  }
  
  /**
   * å¤„ç†éæµå¼ AI è¯·æ±‚
   */
  async processNonStreamingRequest(request: AIRequest): Promise<AIResponse> {
    const startTime = Date.now()

    try {
      // ç¦»çº¿/é™çº§æ¨¡å¼ï¼ˆæœ¬åœ°æ— ç½‘æˆ–æ—  Key æ—¶å¯ç”¨ï¼‰
      if (process.env.WRITEFLOW_AI_OFFLINE === 'true') {
        const content = `ã€ç¦»çº¿æ¨¡å¼ã€‘æ— æ³•è®¿é—®å¤–éƒ¨æ¨¡å‹ï¼Œå·²è¿”å›æ¨¡æ‹Ÿå›å¤ã€‚\n\nè¦ç‚¹: ${request.prompt.slice(0, 120)}${request.prompt.length > 120 ? '...' : ''}`
        const parsedResponse = parseAIResponse(content)
        return {
          content,
          contentBlocks: parsedResponse.content,
          usage: { inputTokens: 0, outputTokens: content.length },
          cost: 0,
          duration: Date.now() - startTime,
          model: 'offline-mock'
        }
      }

      // è·å–æ¨¡å‹é…ç½®
      const modelName = request.model || this.modelManager.getMainAgentModel()
      if (!modelName) {
        throw new Error('æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®')
      }

      const modelProfile = this.findModelProfile(modelName)
      if (!modelProfile) {
        throw new Error(`æ‰¾ä¸åˆ°æ¨¡å‹é…ç½®: ${modelName}`)
      }
      this.providerAdapter = getProviderAdapter(modelProfile.provider)

      // æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”çš„ AI æœåŠ¡
      let response: AIResponse

      switch (modelProfile.provider) {
        case 'anthropic':
        case 'bigdream':
          response = await this.callAnthropicAPI(modelProfile, request)
          break
        case 'deepseek':
          response = await this.callDeepSeekAPI(modelProfile, request)
          break
        case 'openai':
          response = await this.callOpenAIAPI(modelProfile, request)
          break
        case 'kimi':
          response = await this.callKimiAPI(modelProfile, request)
          break
        default:
          throw new Error(`ä¸æ”¯æŒçš„æä¾›å•†: ${modelProfile.provider}`)
      }

      // è®¡ç®—æŒç»­æ—¶é—´
      response.duration = Date.now() - startTime

      // å¦‚æœå¯ç”¨äº†å·¥å…·è°ƒç”¨ï¼Œå¤„ç†å·¥å…·äº¤äº’
      if (request.enableToolCalls && request.allowedTools && request.allowedTools.length > 0) {
        response = await this.processToolInteractions(response, request)
      }

      // æ¸…ç†å¯èƒ½æ®‹ç•™çš„å†…è”æ ‡è®°ï¼ˆæŒ‰ provider é€‚é…å™¨ï¼‰
      response.content = this.providerAdapter.sanitizeText(response.content)
      return response

    } catch (error) {
      logError('AI è¯·æ±‚å¤„ç†å¤±è´¥', error)

      const hint = `\næç¤º: \n- è¯·æ£€æŸ¥ç½‘ç»œè¿é€šæ€§æˆ–ä»£ç†è®¾ç½®\n- å¦‚éœ€ç¦»çº¿æ¼”ç¤º: export WRITEFLOW_AI_OFFLINE=true\n- æˆ–æ­£ç¡®è®¾ç½® API_PROVIDER/AI_MODEL åŠå¯¹åº”çš„ *API_KEY ç¯å¢ƒå˜é‡\n- å¯é€‰ API_BASE_URL è¦†ç›–é»˜è®¤ç½‘å…³`
      return {
        content: `å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}${hint}`,
        usage: { inputTokens: 0, outputTokens: 0 },
        cost: 0,
        duration: Date.now() - startTime,
        model: request.model || 'unknown'
      }
    }
  }
  
  /**
   * è°ƒç”¨ Anthropic API
   */
  private async callAnthropicAPI(profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    const apiKey = this.getAPIKey(profile, ['ANTHROPIC_API_KEY', 'CLAUDE_API_KEY'])
    if (!apiKey) {
      throw new Error('ç¼ºå°‘ Anthropic API å¯†é’¥')
    }
    
    const url = profile.baseURL || 'https://api.anthropic.com/v1/messages'
    
    const payload: any = {
      model: profile.modelName,
      max_tokens: request.maxTokens || profile.maxTokens,
      temperature: request.temperature || 0.3,
      messages: [
        {
          role: 'user',
          content: request.prompt
        }
      ],
      ...(request.systemPrompt && { system: request.systemPrompt })
    }
    // Anthropic ä¹Ÿæ”¯æŒæµå¼
    if (request.stream) {
      payload.stream = true
    }

    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify(payload)
    })
    
    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Anthropic API é”™è¯¯: ${response.status} - ${errorText}`)
    }
    
    if (request.stream) {
      return await this.handleAnthropicStreamingResponse(response, profile, request)
    }

    const data = await response.json()
    
    const rawContent = data.content?.[0]?.text || 'æ— å“åº”å†…å®¹'
    const parsedResponse = parseAIResponse(rawContent)
    
    // åˆ†æå†…å®¹å¹¶åˆ›å»ºå¯æŠ˜å çš„å†…å®¹å—
    const collapsibleBlocks = this.createCollapsibleContentBlocks(rawContent)
    
    return {
      content: rawContent,
      contentBlocks: collapsibleBlocks.length > 0 ? collapsibleBlocks : parsedResponse.content,
      usage: {
        inputTokens: data.usage?.input_tokens || 0,
        outputTokens: data.usage?.output_tokens || 0
      },
      cost: this.calculateCost(data.usage, profile.provider),
      duration: 0, // å°†åœ¨å¤–éƒ¨è®¾ç½®
      model: profile.modelName
    }
  }

  /**
   * å¤„ç† Anthropic SSE æµå¼å“åº”
   * äº‹ä»¶ç±»å‹å‚è§å®˜æ–¹ï¼šmessage_start/content_block_start/content_block_delta/.../message_delta/message_stop
   */
  private async handleAnthropicStreamingResponse(response: Response, profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    if (!response.body) throw new Error('Response body is null')

    const reader = response.body.getReader()
    const decoder = new TextDecoder('utf-8')
    let buffer = ''
    let content = ''

    const responseManager = getResponseStateManager()
    const streamId = `stream-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
    responseManager.startStreaming(streamId)
    const isInteractiveUI = (global as any).WRITEFLOW_INTERACTIVE === true
    const useConsoleProgress = typeof request.onToken !== 'function' && !isInteractiveUI
    if (useConsoleProgress) {
      startStreamingProgress({ style: 'claude', showDuration: true, showTokens: true, showInterruptHint: true })
    }

    try {
      while (true) {
        const { value, done } = await reader.read()
        if (done) break
        buffer += decoder.decode(value, { stream: true })

        const parts = buffer.split('\n\n')
        buffer = parts.pop() || ''
        for (const part of parts) {
          const line = part.trim()
          if (!line.startsWith('data:')) continue
          const dataStr = line.slice(5).trim()
          if (!dataStr || dataStr === '[DONE]') continue
          try {
            const evt = JSON.parse(dataStr)
            // content_block_delta æºå¸¦æ–‡æœ¬å¢é‡
            if (evt.type === 'content_block_delta' && evt.delta?.type === 'text_delta' && evt.delta?.text) {
              const deltaText = evt.delta.text as string
              content += deltaText
              const estimated = Math.ceil(content.length / 4)
              responseManager.updateStreamingProgress(streamId, { tokenCount: estimated, characterCount: content.length, chunkSize: deltaText.length, contentType: 'text' })
              if (typeof request.onToken === 'function') {
                try { request.onToken(deltaText) } catch {}
              } else if (!isInteractiveUI) {
                process.stdout.write(deltaText)
              }
            }
          } catch {
            // å¿½ç•¥è§£æå¤±è´¥
          }
        }
      }
    } finally {
      reader.releaseLock()
      if (useConsoleProgress) stopStreamingProgress()
    }

    const finalTokens = Math.ceil(content.length / 4)
    const stats = responseManager.completeStreaming(streamId, finalTokens)
    const parsedResponse = parseAIResponse(content)
    
    // åˆ†æå†…å®¹å¹¶åˆ›å»ºå¯æŠ˜å çš„å†…å®¹å—
    const collapsibleBlocks = this.createCollapsibleContentBlocks(content)

    return {
      content,
      contentBlocks: collapsibleBlocks.length > 0 ? collapsibleBlocks : parsedResponse.content,
      usage: { inputTokens: 0, outputTokens: finalTokens },
      cost: 0,
      duration: stats.duration,
      model: profile.modelName,
    }
  }
  
  /**
   * è°ƒç”¨ DeepSeek API - æ”¯æŒåŸç”Ÿ function calling
   */
  private async callDeepSeekAPI(profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    const apiKey = this.getAPIKey(profile, ['DEEPSEEK_API_KEY'])
    if (!apiKey) {
      throw new Error('ç¼ºå°‘ DeepSeek API å¯†é’¥')
    }
    
    const url = profile.baseURL || 'https://api.deepseek.com/chat/completions'
    
    // å¦‚æœå¯ç”¨äº†å·¥å…·è°ƒç”¨ï¼Œåˆ™ä½¿ç”¨å¤šè½®å¯¹è¯æœºåˆ¶
    if (request.enableToolCalls && request.allowedTools && request.allowedTools.length > 0) {
      return await this.callDeepSeekWithTools(url, apiKey, profile, request)
    }
    
    // æ ‡å‡†è°ƒç”¨ï¼ˆæ— å·¥å…·ï¼‰
    const messages = []
    if (request.systemPrompt) {
      messages.push({ role: 'system', content: request.systemPrompt })
    }
    messages.push({ role: 'user', content: request.prompt })
    
    const payload = {
      model: profile.modelName,
      messages,
      max_tokens: request.maxTokens || profile.maxTokens,
      temperature: request.temperature || 0.3,
      stream: request.stream || false
    }
    
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(payload)
    })
    
    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`DeepSeek API é”™è¯¯: ${response.status} - ${errorText}`)
    }
    
    // å¦‚æœæ˜¯æµå¼è¯·æ±‚ï¼Œå¤„ç†æµå¼å“åº”
    if (request.stream) {
      return await this.handleStreamingResponse(response, profile, request)
    }
    
    // éæµå¼å¤„ç†
    const data = await response.json()
    
    const rawContent = data.choices?.[0]?.message?.content || 'æ— å“åº”å†…å®¹'
    const parsedResponse = parseAIResponse(rawContent)
    
    // åˆ†æå†…å®¹å¹¶åˆ›å»ºå¯æŠ˜å çš„å†…å®¹å—
    const collapsibleBlocks = this.createCollapsibleContentBlocks(rawContent)
    
    return {
      content: rawContent,
      contentBlocks: collapsibleBlocks.length > 0 ? collapsibleBlocks : parsedResponse.content,
      usage: {
        inputTokens: data.usage?.prompt_tokens || 0,
        outputTokens: data.usage?.completion_tokens || 0
      },
      cost: this.calculateCost(data.usage, profile.provider),
      duration: 0,
      model: profile.modelName
    }
  }
  
  /**
   * å¤„ç†æµå¼å“åº”
   */
  private async handleStreamingResponse(response: Response, profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    if (!response.body) {
      throw new Error('Response body is null')
    }

    const reader = response.body.getReader()
    const decoder = new TextDecoder('utf-8')
    let buffer = ''
    let content = ''
    let usage = { inputTokens: 0, outputTokens: 0 }
    let pipeClosed = false
    
    // è·å–å“åº”çŠ¶æ€ç®¡ç†å™¨å¹¶å¼€å§‹æµå¼è·Ÿè¸ªï¼ˆåœ¨äº¤äº’å¼ UI ä¸‹ç¦ç”¨æ§åˆ¶å°è¾“å‡ºï¼‰
    const responseManager = getResponseStateManager()
    const streamId = `stream-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
    responseManager.startStreaming(streamId)
    const isInteractiveUI = (global as any).WRITEFLOW_INTERACTIVE === true
    const useConsoleProgress = typeof request.onToken !== 'function' && !isInteractiveUI
    if (useConsoleProgress) {
      startStreamingProgress({ style: 'claude', showTokens: true, showDuration: true, showInterruptHint: true })
    }
    
    // ç›‘å¬ç®¡é“å…³é—­äº‹ä»¶
    process.stdout.on('error', (error) => {
      if ((error as any).code === 'EPIPE') {
        pipeClosed = true
      }
    })
    
    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) break

        buffer += decoder.decode(value, { stream: true })
        const parts = buffer.split('\n\n')
        buffer = parts.pop() || ''

        for (const part of parts) {
          const line = part.trim()
          if (!line.startsWith('data:')) continue
          const dataStr = line.slice(5).trim()
          if (dataStr === '[DONE]') continue
          try {
            const data = JSON.parse(dataStr)
            const delta = data.choices?.[0]?.delta?.content
            if (delta) {
              content += delta
              const estimatedTokens = Math.ceil(content.length / 4)
              responseManager.updateStreamingProgress(streamId, { tokenCount: estimatedTokens, characterCount: content.length, chunkSize: delta.length, contentType: 'text' })
              if (typeof request.onToken === 'function') {
                try { request.onToken(delta) } catch {}
              } else if (!isInteractiveUI && !process.stdout.destroyed && !pipeClosed) {
                try {
                  const canWrite = process.stdout.write(delta)
                  if (!canWrite) process.stdout.once('drain', () => {})
                } catch {
                  pipeClosed = true
                }
              }
            }
            if (data.usage) {
              usage.inputTokens = data.usage.prompt_tokens || 0
              usage.outputTokens = data.usage.completion_tokens || 0
            }
          } catch {
            // å¿½ç•¥è§£æå¤±è´¥
          }
        }
      }
    } finally {
      reader.releaseLock()
    }
    
    // å®Œæˆæµå¼å“åº”å¹¶è·å–ç»Ÿè®¡ä¿¡æ¯
    const finalTokenCount = usage.outputTokens || Math.ceil(content.length / 4)
    const streamingStats = responseManager.completeStreaming(streamId, finalTokenCount)
    const parsedResponse = parseAIResponse(content)
    
    // åœæ­¢è¿›åº¦æŒ‡ç¤ºå™¨ï¼ˆä»…æ§åˆ¶å°æ¨¡å¼ï¼‰
    if (useConsoleProgress) {
      stopStreamingProgress()
    }
    
    // åœ¨æµå¼å¤„ç†å®Œæˆåï¼Œæä¾›æ ¼å¼åŒ–åçš„æœ€ç»ˆè¾“å‡º
    if (useConsoleProgress) {
      try {
        const formatter = getOutputFormatter({
          enableColors: process.stdout.isTTY,
          theme: process.env.WRITEFLOW_THEME === 'light' ? 'light' : 'dark'
        })
        const formatted = formatter.formatStreamOutput(content, { maxWidth: 80 })
        if (formatted.hasCodeBlocks && formatted.codeBlockCount > 0) {
          process.stderr.write(`\n${formatter.formatSuccess(`åŒ…å« ${formatted.codeBlockCount} ä¸ªä»£ç å—çš„å†…å®¹å·²è¾“å‡º`)}\n`)
        }
      } catch (formatError) {
        console.warn(`æœ€ç»ˆæ ¼å¼åŒ–å¤±è´¥: ${formatError}`)
      }
    }
    
    return {
      content,
      contentBlocks: parsedResponse.content,
      usage,
      cost: this.calculateCost({
        prompt_tokens: usage.inputTokens,
        completion_tokens: usage.outputTokens
      }, profile.provider),
      duration: streamingStats.duration,
      model: profile.modelName,
      // æ·»åŠ æµå¼æ€§èƒ½ç»Ÿè®¡ï¼ˆå¯é€‰ï¼‰
      streamingStats: {
        duration: streamingStats.duration,
        tokenCount: finalTokenCount,
        tokensPerSecond: streamingStats.tokensPerSecond,
        startTime: streamingStats.startTime,
        endTime: streamingStats.endTime
      }
    }
  }

  /**
   * è°ƒç”¨ OpenAI API
   */
  private async callOpenAIAPI(profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    const apiKey = this.getAPIKey(profile, ['OPENAI_API_KEY'])
    if (!apiKey) {
      throw new Error('ç¼ºå°‘ OpenAI API å¯†é’¥')
    }
    
    const url = profile.baseURL || 'https://api.openai.com/v1/chat/completions'
    
    const messages = []
    if (request.systemPrompt) {
      messages.push({ role: 'system', content: request.systemPrompt })
    }
    messages.push({ role: 'user', content: request.prompt })
    
    const payload: any = {
      model: profile.modelName,
      messages,
      max_tokens: request.maxTokens || profile.maxTokens,
      temperature: request.temperature || 0.3,
    }
    if (request.stream) payload.stream = true
    
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(payload)
    })
    
    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`OpenAI API é”™è¯¯: ${response.status} - ${errorText}`)
    }
    if (request.stream) {
      return await this.handleStreamingResponse(response, profile, request)
    }

    const data = await response.json()
    
    const rawContent = data.choices?.[0]?.message?.content || 'æ— å“åº”å†…å®¹'
    const parsedResponse = parseAIResponse(rawContent)
    
    // åˆ†æå†…å®¹å¹¶åˆ›å»ºå¯æŠ˜å çš„å†…å®¹å—
    const collapsibleBlocks = this.createCollapsibleContentBlocks(rawContent)
    
    return {
      content: rawContent,
      contentBlocks: collapsibleBlocks.length > 0 ? collapsibleBlocks : parsedResponse.content,
      usage: {
        inputTokens: data.usage?.prompt_tokens || 0,
        outputTokens: data.usage?.completion_tokens || 0
      },
      cost: this.calculateCost(data.usage, profile.provider),
      duration: 0,
      model: profile.modelName
    }
  }
  
  /**
   * è°ƒç”¨ Kimi API
   */
  private async callKimiAPI(profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    const apiKey = this.getAPIKey(profile, ['KIMI_API_KEY', 'MOONSHOT_API_KEY'])
    if (!apiKey) {
      throw new Error('ç¼ºå°‘ Kimi API å¯†é’¥')
    }
    
    const url = profile.baseURL || 'https://api.moonshot.cn/v1/chat/completions'
    
    const messages = []
    if (request.systemPrompt) {
      messages.push({ role: 'system', content: request.systemPrompt })
    }
    messages.push({ role: 'user', content: request.prompt })
    
    const payload: any = {
      model: profile.modelName,
      messages,
      max_tokens: request.maxTokens || profile.maxTokens,
      temperature: request.temperature || 0.3,
    }
    if (request.stream) payload.stream = true
    
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(payload)
    })
    
    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Kimi API é”™è¯¯: ${response.status} - ${errorText}`)
    }
    if (request.stream) {
      return await this.handleStreamingResponse(response, profile, request)
    }

    const data = await response.json()
    
    const rawContent = data.choices?.[0]?.message?.content || 'æ— å“åº”å†…å®¹'
    const parsedResponse = parseAIResponse(rawContent)
    
    // åˆ†æå†…å®¹å¹¶åˆ›å»ºå¯æŠ˜å çš„å†…å®¹å—
    const collapsibleBlocks = this.createCollapsibleContentBlocks(rawContent)
    
    return {
      content: rawContent,
      contentBlocks: collapsibleBlocks.length > 0 ? collapsibleBlocks : parsedResponse.content,
      usage: {
        inputTokens: data.usage?.prompt_tokens || 0,
        outputTokens: data.usage?.completion_tokens || 0
      },
      cost: this.calculateCost(data.usage, profile.provider),
      duration: 0,
      model: profile.modelName
    }
  }
  
  /**
   * è·å–é»˜è®¤æ¨¡å‹åç§°
   */
  private getDefaultModelName(): string {
    // ä¼˜å…ˆä½¿ç”¨ AI_MODEL ç¯å¢ƒå˜é‡
    if (process.env.AI_MODEL) {
      return process.env.AI_MODEL
    }
    
    // å…¶æ¬¡ä½¿ç”¨ API_PROVIDER æ¨æ–­æ¨¡å‹
    const provider = process.env.API_PROVIDER
    switch (provider) {
      case 'deepseek':
        return 'deepseek-chat'
      case 'qwen3':
        return 'qwen-turbo'
      case 'glm4.5':
        return 'glm-4-flash'
      case 'anthropic':
        return 'claude-3-sonnet-20240229'
      case 'openai':
        return 'gpt-3.5-turbo'
      case 'kimi':
        return 'moonshot-v1-8k'
      default:
        // æœ€åæ£€æŸ¥æœ‰å“ªäº› API Key å¯ç”¨ï¼Œæ™ºèƒ½é€‰æ‹©é»˜è®¤æ¨¡å‹
        if (process.env.DEEPSEEK_API_KEY) return 'deepseek-chat'
        if (process.env.ANTHROPIC_API_KEY) return 'claude-3-sonnet-20240229'
        if (process.env.OPENAI_API_KEY) return 'gpt-3.5-turbo'
        if (process.env.KIMI_API_KEY) return 'moonshot-v1-8k'
        if (process.env.GLM_API_KEY) return 'glm-4-flash'
        
        return 'deepseek-chat' // æœ€ç»ˆé»˜è®¤ä½¿ç”¨ DeepSeek
    }
  }

  /**
   * æ ¹æ®æ¨¡å‹åç§°åˆ›å»ºä¸´æ—¶çš„æ¨¡å‹é…ç½®
   */
  private createTempModelProfile(modelName: string): ModelProfile | null {
    // æ ¹æ®æ¨¡å‹åç§°æ¨æ–­æä¾›å•†
    let provider: string
    let baseURL: string | undefined
    
    if (modelName.includes('deepseek')) {
      provider = 'deepseek'
      baseURL = 'https://api.deepseek.com/v1/chat/completions'
    } else if (modelName.includes('claude') || modelName.includes('anthropic')) {
      provider = 'anthropic'
      baseURL = 'https://api.anthropic.com/v1/messages'
    } else if (modelName.includes('gpt') || modelName.includes('openai')) {
      provider = 'openai'
      baseURL = 'https://api.openai.com/v1/chat/completions'
    } else if (modelName.includes('moonshot') || modelName.includes('kimi')) {
      provider = 'kimi'
      baseURL = 'https://api.moonshot.cn/v1/chat/completions'
    } else if (modelName.includes('qwen')) {
      provider = 'openai' // Qwen ä½¿ç”¨ OpenAI å…¼å®¹åè®®
      baseURL = process.env.API_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1'
    } else if (modelName.includes('glm')) {
      provider = 'openai' // GLM ä½¿ç”¨ OpenAI å…¼å®¹åè®®
      baseURL = process.env.API_BASE_URL || 'https://open.bigmodel.cn/api/paas/v4'
    } else {
      // æ ¹æ®ç¯å¢ƒå˜é‡æ¨æ–­
      provider = process.env.API_PROVIDER || 'deepseek'
      baseURL = process.env.API_BASE_URL
    }

    // åˆ›å»ºä¸´æ—¶çš„æ¨¡å‹é…ç½®
    const profile: ModelProfile = {
      name: `temp-${modelName}`,
      provider: provider as any,
      modelName: modelName,
      baseURL: baseURL,
      apiKey: this.getAPIKeyForProvider(provider),
      maxTokens: 4000,
      contextLength: 128000,
      isActive: true
    }

    // éªŒè¯ API å¯†é’¥æ˜¯å¦å¯ç”¨
    if (!profile.apiKey) {
      console.warn(`æ‰¾ä¸åˆ° ${provider} çš„ API å¯†é’¥`)
      return null
    }

    return profile
  }

  /**
   * æ ¹æ®æä¾›å•†è·å– API å¯†é’¥
   */
  private getAPIKeyForProvider(provider: string): string {
    const envKeys = {
      anthropic: ['ANTHROPIC_API_KEY', 'CLAUDE_API_KEY'],
      deepseek: ['DEEPSEEK_API_KEY'],
      openai: ['OPENAI_API_KEY'],
      kimi: ['KIMI_API_KEY', 'MOONSHOT_API_KEY'],
      qwen: ['QWEN_API_KEY', 'DASHSCOPE_API_KEY'],
      glm: ['GLM_API_KEY', 'ZHIPUAI_API_KEY']
    }

    const keys = envKeys[provider as keyof typeof envKeys] || []
    for (const key of keys) {
      const value = process.env[key]
      if (value) return value
    }

    return ''
  }

  /**
   * è·å– API å¯†é’¥
   */
  private getAPIKey(profile: ModelProfile, envKeys: string[]): string | undefined {
    // ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„å¯†é’¥
    if (profile.apiKey) {
      return profile.apiKey
    }
    
    // ä»ç¯å¢ƒå˜é‡è·å–
    for (const key of envKeys) {
      const value = process.env[key]
      if (value) {
        return value
      }
    }
    
    return undefined
  }
  
  /**
   * æŸ¥æ‰¾æ¨¡å‹é…ç½®
   */
  private findModelProfile(modelName: string): ModelProfile | null {
    const profiles = this.modelManager.getAllProfiles()
    return profiles.find(p => p.modelName === modelName || p.name === modelName) || null
  }
  
  /**
   * è®¡ç®—æˆæœ¬
   */
  private calculateCost(usage: any, provider: string): number {
    if (!usage) return 0
    
    // ç®€åŒ–çš„æˆæœ¬è®¡ç®—
    const inputTokens = usage.prompt_tokens || usage.input_tokens || 0
    const outputTokens = usage.completion_tokens || usage.output_tokens || 0
    
    // åŸºç¡€è´¹ç‡ï¼ˆå®é™…è´¹ç‡åº”è¯¥ä»æ¨¡å‹é…ç½®ä¸­è·å–ï¼‰
    const rates = {
      anthropic: { input: 0.000003, output: 0.000015 },
      deepseek: { input: 0.00000027, output: 0.0000011 },
      openai: { input: 0.0000025, output: 0.00001 },
      kimi: { input: 0.000001, output: 0.000002 },
      bigdream: { input: 0.000003, output: 0.000015 }
    }
    
    const rate = rates[provider as keyof typeof rates] || { input: 0, output: 0 }
    return inputTokens * rate.input + outputTokens * rate.output
  }

  /**
   * è°ƒç”¨ DeepSeek API çš„å·¥å…·è°ƒç”¨ç‰ˆæœ¬ - å¤šè½®å¯¹è¯
   */
  private async callDeepSeekWithTools(url: string, apiKey: string, profile: ModelProfile, request: AIRequest): Promise<AIResponse> {
    const messages = []
    if (request.systemPrompt) {
      messages.push({ role: 'system', content: request.systemPrompt })
    }
    messages.push({ role: 'user', content: request.prompt })

    // è½¬æ¢å·¥å…·å®šä¹‰
    const tools = await this.convertToolsToDeepSeekFormat(request.allowedTools!)
    
    // å¦‚æœæ²¡æœ‰å·¥å…·æˆ–å·¥å…·ä¸ºç©ºï¼Œå›é€€åˆ°æ ‡å‡†è°ƒç”¨
    if (!tools || tools.length === 0) {
      return await this.callDeepSeekAPI(profile, { ...request, enableToolCalls: false, allowedTools: undefined })
    }
    
    let totalInputTokens = 0
    let totalOutputTokens = 0
    let conversationHistory = ''
    let maxIterations = 5
    let iteration = 0
    let consecutiveFailures = 0
    const maxConsecutiveFailures = 2
    let lastRoundHadTodoUpdate = false
    
    // æ·»åŠ ç”¨æˆ·è¯·æ±‚åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    const userRequestTokens = estimateTokens(request.prompt)
    this.contextManager.addEntry({
      role: 'user',
      content: request.prompt,
      tokens: userRequestTokens,
      importance: this.contextManager.calculateImportance(request.prompt, 'conversation'),
      type: 'conversation'
    })

    while (iteration < maxIterations) {
      const iterationStartTime = Date.now()
      console.log(`ğŸ”„ AI æ­£åœ¨æ€è€ƒå’Œæ‰§è¡Œ...`)
      
      const payload: any = {
        model: profile.modelName,
        messages,
        tools: lastRoundHadTodoUpdate ? [] : tools,
        tool_choice: lastRoundHadTodoUpdate ? 'none' : 'auto',
        max_tokens: request.maxTokens || profile.maxTokens,
        temperature: request.temperature || 0.3,
        // æ³¨æ„ï¼šå¸¦å·¥å…·è°ƒç”¨çš„æµå¼å“åº”æ˜¯ SSEï¼ŒåŒ…å« `data:` å‰ç¼€ï¼Œ
        // è¿™é‡Œç»Ÿä¸€å…³é—­æµå¼ï¼Œæ”¹ä¸ºä¸€æ¬¡æ€§ JSONï¼Œé¿å…è§£ææŠ¥é”™ã€‚
        stream: false
      }

      const response: any = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify(payload)
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`DeepSeek API é”™è¯¯: ${response.status} - ${errorText}`)
      }

      let data: any
      try {
        data = await response.json()
      } catch (e) {
        // æŸäº›ç½‘å…³å¯èƒ½ä»è¿”å› SSEï¼Œè¿™é‡Œå…œåº•è¯»å–æ–‡æœ¬å¹¶å°è¯•æå–æœ€åä¸€ä¸ª data: JSON
        const text = await response.text()
        const lines = text.split(/\n/).map((l: string) => l.trim()).filter(Boolean)
        const lastData = [...lines].reverse().find((l: string) => l.startsWith('data:'))
        if (!lastData) throw e
        const jsonStr = lastData.replace(/^data:\s*/, '')
        data = JSON.parse(jsonStr)
      }
      const message: any = data.choices?.[0]?.message
      // å¤„ç† DeepSeek å†…è”å·¥å…·æ ‡è®°ï¼ˆè‹¥å­˜åœ¨ï¼‰
      if (message && typeof message.content === 'string' && message.content.includes('toolâ–')) {
        const inline = this.extractInlineToolCalls(message.content)
        message.content = inline.cleaned
        if (inline.calls.length > 0) {
          message.tool_calls = (message.tool_calls || []).concat(
            inline.calls.map((c: any) => ({
              type: 'function',
              id: `inline_${Date.now()}_${Math.random().toString(36).slice(2)}`,
              function: {
                name: c.name,
                arguments: JSON.stringify(c.args)
              }
            }))
          )
        }
      }
      
      const promptTokens = data.usage?.prompt_tokens || 0
      const completionTokens = data.usage?.completion_tokens || 0
      
      totalInputTokens += promptTokens
      totalOutputTokens += completionTokens
      
      // è®¡ç®—æˆæœ¬å¹¶è®°å½•åˆ° CostTracker
      const cost = this.calculateCost(data.usage, profile.provider)
      const duration = Date.now() - iterationStartTime
      
      addCostEntry(
        profile.modelName,
        promptTokens,
        completionTokens,
        cost,
        duration,
        message.tool_calls && message.tool_calls.length > 0 ? 'tool' : 'chat'
      )

      // å¦‚æœAIæ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œåˆ™å¯¹è¯ç»“æŸ
      if (!message.tool_calls || message.tool_calls.length === 0) {
        conversationHistory += this.sanitizeLLMArtifacts(message.content)
        
        // æ·»åŠ AIå“åº”åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        const responseTokens = estimateTokens(message.content)
        this.contextManager.addEntry({
          role: 'assistant',
          content: message.content,
          tokens: responseTokens,
          importance: this.contextManager.calculateImportance(message.content, 'conversation'),
          type: 'conversation'
        })

        // è‹¥ä¸Šä¸€è½®åˆšè¿›è¡Œäº† todo_* æ›´æ–°ï¼Œè¿™ä¸€è½®æ˜¯æ­£æ–‡ç”Ÿæˆï¼š
        // 1) è‡ªåŠ¨å°†å½“å‰ in_progress ç½®ä¸º completed
        // 2) è‹¥è¾“å‡ºæ–‡æœ¬è¶³å¤Ÿå®Œæ•´ï¼ˆé•¿åº¦é˜ˆå€¼ï¼‰ï¼Œå°†å‰©ä½™ pending ä¹Ÿæ ‡è®°ä¸º completedï¼ˆé¿å…ä¸€æ¬¡æ€§å®Œæˆçš„åœºæ™¯è¿›åº¦ä¸åŒæ­¥ï¼‰
        if (lastRoundHadTodoUpdate) {
          try {
            const { TodoManager } = await import('../../tools/TodoManager.js')
            const mgr = new TodoManager(process.env.WRITEFLOW_SESSION_ID)
            const current = await mgr.getCurrentTask()
            let changed = false
            if (current) {
              await mgr.completeTask(current.id)
              changed = true
            }
            // å¦‚æœæ–‡æœ¬è¾ƒé•¿ï¼Œè®¤ä¸ºæœ¬è½®å®Œæˆäº†ä¸»è¦å·¥ä½œï¼Œæ‰¹é‡åŒæ­¥å‰©ä½™å¾…å¤„ç†ä¸ºå®Œæˆ
            const substantial = (message.content || '').length >= 800 || conversationHistory.length >= 1200
            if (substantial) {
              const all = await mgr.getAllTodos()
              const pendingIds = all.filter(t => t.status === 'pending').map(t => t.id)
              if (pendingIds.length > 0) {
                await mgr.batchUpdateStatus(pendingIds, 'completed' as any)
                changed = true
              }
            }
            if (changed) emitReminderEvent('todo:changed', { agentId: 'deepseek-ai' })
          } catch (e) {
            console.warn('âš ï¸ è‡ªåŠ¨å®Œæˆå½“å‰ä»»åŠ¡å¤±è´¥:', (e as Error)?.message)
          }
        }
        
        return {
          content: conversationHistory,
          usage: {
            inputTokens: totalInputTokens,
            outputTokens: totalOutputTokens
          },
          cost: this.calculateCost({ prompt_tokens: totalInputTokens, completion_tokens: totalOutputTokens }, profile.provider),
          duration: 0,
          model: profile.modelName,
          hasToolInteraction: iteration > 0
        }
      }

      // AI è°ƒç”¨äº†å·¥å…·ï¼Œæ·»åŠ  AI æ¶ˆæ¯åˆ°å¯¹è¯å†å²
      messages.push(message)
      
      // æ‰§è¡Œå·¥å…·è°ƒç”¨
      let currentRoundHasFailures = false
      let currentRoundHasTodoUpdate = false
      for (const toolCall of message.tool_calls) {
        // æ˜¾ç¤ºç®€æ´çš„å·¥å…·æ‰§è¡Œä¿¡æ¯ï¼ˆå·²é€šè¿‡ displayToolExecution å¤„ç†ï¼‰
        this.displayToolExecution(toolCall)
        
        // è¿‡æ»¤TODOå·¥å…·çš„æ‰§è¡Œä¿¡æ¯ï¼Œä¸æ·»åŠ åˆ°conversation historyä¸­
        if (!toolCall.function.name.includes('todo')) {
          conversationHistory += `\nAI: [è°ƒç”¨ ${toolCall.function.name} å·¥å…·] æ­£åœ¨æ‰§è¡Œ...\n`
        }
        
        try {
          const toolResult = await this.executeDeepSeekToolCall(toolCall)
          
          if (toolResult.success) {
            // æ˜¾ç¤ºç®€æ´çš„ç»“æœæ¶ˆæ¯ï¼ˆé€šè¿‡ createToolResultBlock æˆ–ç›´æ¥è¾“å‡ºï¼‰
            if (!toolCall.function.name.includes('todo')) {
              const briefMessage = this.getBriefResultMessage(toolCall.function.name, 'success', toolResult.result)
              const resultLines = toolResult.result.split('\n').length
              console.log(`${briefMessage} ${format.dim(`(${resultLines} lines, Ctrl+R to expand)`)}`)
              conversationHistory += `${toolCall.function.name}å·¥å…·: ${toolResult.result}\n`
              
              // æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœåˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
              const toolResultTokens = estimateTokens(toolResult.result)
              this.contextManager.addEntry({
                role: 'tool',
                content: `${toolCall.function.name}: ${toolResult.result}`,
                tokens: toolResultTokens,
                importance: this.contextManager.calculateImportance(toolResult.result, 'tool_use'),
                type: 'tool_use'
              })
            }
            consecutiveFailures = 0 // é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
            if (toolCall.function.name.startsWith('todo_')) {
              currentRoundHasTodoUpdate = true
            }
          } else {
            // æ˜¾ç¤ºç®€æ´çš„é”™è¯¯æ¶ˆæ¯
            if (!toolCall.function.name.includes('todo')) {
              const briefMessage = this.getBriefResultMessage(toolCall.function.name, 'error', toolResult.error || 'æ‰§è¡Œå¤±è´¥')
              console.log(`${briefMessage} ${format.dim('(error)')}`)
              conversationHistory += `${toolCall.function.name}å·¥å…·: ${toolResult.error}\n`
            }
            currentRoundHasFailures = true
          }
          
          // å°†å·¥å…·æ‰§è¡Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
          messages.push({
            role: 'tool',
            tool_call_id: toolCall.id,
            content: toolResult.success ? toolResult.result : toolResult.error || 'æ‰§è¡Œå¤±è´¥'
          })
        } catch (error) {
          const errorMsg = `å·¥å…·æ‰§è¡Œå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
          if (!toolCall.function.name.includes('todo')) {
            console.log(`âŒ [${toolCall.function.name}] ${errorMsg} ${format.dim('(exception)')}`)
            conversationHistory += `${toolCall.function.name}å·¥å…·: ${errorMsg}\n`
          }
          currentRoundHasFailures = true
          
          messages.push({
            role: 'tool',
            tool_call_id: toolCall.id,
            content: errorMsg
          })
        }
      }

      // æ£€æŸ¥è¿ç»­å¤±è´¥
      if (currentRoundHasFailures) {
        consecutiveFailures++
        if (consecutiveFailures >= maxConsecutiveFailures) {
          console.log(`âš ï¸  è¿ç»­å¤±è´¥ ${consecutiveFailures} æ¬¡ï¼Œç»ˆæ­¢å·¥å…·è°ƒç”¨`)
          return {
            content: conversationHistory + '\nç³»ç»Ÿæç¤ºï¼šè¿ç»­å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥å‚æ•°æ ¼å¼å’Œå·¥å…·ä½¿ç”¨æ–¹æ³•ã€‚',
            usage: {
              inputTokens: totalInputTokens,
              outputTokens: totalOutputTokens
            },
            cost: this.calculateCost({ prompt_tokens: totalInputTokens, completion_tokens: totalOutputTokens }, profile.provider),
            duration: 0,
            model: profile.modelName,
            hasToolInteraction: true
          }
        }
      }
      // è‹¥æœ¬è½®æˆåŠŸæ›´æ–°äº† todo_*ï¼Œä¸‹ä¸€è½®ç¦ç”¨å·¥å…·å¹¶å¼ºåˆ¶æ­£æ–‡ç”Ÿæˆ
      if (currentRoundHasTodoUpdate) {
        lastRoundHadTodoUpdate = true
        messages.push({
          role: 'user',
          content: 'å·²æ›´æ–°ä»»åŠ¡åˆ—è¡¨ã€‚ç°åœ¨è¯·æ ¹æ®å½“å‰ä»»åŠ¡ç›´æ¥ç”Ÿæˆæ­£æ–‡å†…å®¹ï¼Œä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ã€‚è¯·å¼€å§‹å†™ä½œã€‚'
        })
      } else {
        lastRoundHadTodoUpdate = false
      }

      iteration++
    }

    // è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
    return {
      content: conversationHistory + '\n[ç³»ç»Ÿ] å¯¹è¯è¾¾åˆ°è½®æ¬¡ä¸Šé™ã€‚è¯·ç»§ç»­ç›´æ¥ç”Ÿæˆæ­£æ–‡å†…å®¹ã€‚',
      usage: {
        inputTokens: totalInputTokens,
        outputTokens: totalOutputTokens
      },
      cost: this.calculateCost({ prompt_tokens: totalInputTokens, completion_tokens: totalOutputTokens }, profile.provider),
      duration: 0,
      model: profile.modelName,
      hasToolInteraction: true
    }
  }

  /**
   * è½¬æ¢å·¥å…·å®šä¹‰ä¸º DeepSeek API æ ¼å¼ - ä½¿ç”¨æ–°çš„å·¥å…·ç³»ç»Ÿ
   * ä¼˜å…ˆè€ƒè™‘æƒé™å’Œå¯ç”¨æ€§æ£€æŸ¥
   */
  private async convertToolsToDeepSeekFormat(allowedTools: string[]): Promise<any[]> {
    const tools = []
    
    // å¦‚æœæ²¡æœ‰å…è®¸çš„å·¥å…·ï¼Œç›´æ¥è¿”å›ç©ºæ•°ç»„
    if (!allowedTools || allowedTools.length === 0) {
      return []
    }
    
    // è·å–å½“å‰å¯ç”¨çš„å·¥å…·ï¼ˆè€ƒè™‘æƒé™ï¼‰
    const availableTools = this.toolOrchestrator.getAvailableTools()
    const availableToolNames = new Set(availableTools.map(t => t.name))
    
    for (const toolName of allowedTools) {
      // æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨å…è®¸çš„å·¥å…·åˆ—è¡¨ä¸­
      // å†…ç½®å…¼å®¹: ä¸€äº›å†™ä½œåŸŸå·¥å…·ï¼ˆå¦‚ todo_*ã€exit_plan_modeï¼‰æœªæ¥å…¥ç¼–æ’å™¨
      // è¿™é‡Œç›´æ¥æä¾›æœ€å° JSON-Schema æè¿°ï¼Œé¿å…æ§åˆ¶å°å‡ºç°å™ªéŸ³æ—¥å¿—å¹¶å…è®¸æ¨¡å‹åŸç”Ÿå‡½æ•°è°ƒç”¨ã€‚
      if (!availableToolNames.has(toolName)) {
        if (toolName === 'todo_write') {
          tools.push({
            type: 'function',
            function: {
              name: 'todo_write',
              description: 'ä»…ç”¨äºè¿›åº¦è¿½è¸ªçš„åå°å·¥å…·ï¼Œæ›´æ–°ä»»åŠ¡çŠ¶æ€ã€‚é‡è¦ï¼šè°ƒç”¨æ­¤å·¥å…·åå¿…é¡»ç»§ç»­æ‰§è¡Œç”¨æˆ·è¯·æ±‚çš„ä¸»è¦ä»»åŠ¡ï¼ˆå¦‚å†™æ•…äº‹ã€æ–‡ç« ç­‰ï¼‰ã€‚æ­¤å·¥å…·ä¸æ›¿ä»£å®é™…å†…å®¹ç”Ÿæˆã€‚',
              parameters: {
                type: 'object',
                properties: {
                  todos: {
                    type: 'array',
                    items: {
                      type: 'object',
                      properties: {
                        id: { type: 'string' },
                        content: { type: 'string' },
                        activeForm: { type: 'string' },
                        status: { type: 'string', enum: ['pending','in_progress','completed'] },
                        priority: { type: 'string', enum: ['high','medium','low'] }
                      },
                      required: ['id','content','activeForm','status']
                    }
                  }
                },
                required: ['todos']
              }
            }
          })
          continue
        }
        if (toolName === 'todo_read') {
          tools.push({
            type: 'function',
            function: {
              name: 'todo_read',
              description: 'è¯»å–å½“å‰ä»»åŠ¡åˆ—è¡¨å¹¶è¿”å› JSONã€‚',
              parameters: { type: 'object', properties: {}, additionalProperties: false }
            }
          })
          continue
        }
        if (toolName === 'exit_plan_mode') {
          tools.push({
            type: 'function',
            function: {
              name: 'exit_plan_mode',
              description: 'é€€å‡ºè®¡åˆ’æ¨¡å¼ï¼Œæ¢å¤æ­£å¸¸å¯¹è¯ã€‚',
              parameters: { type: 'object', properties: { plan: { type: 'string' } }, required: [] }
            }
          })
          continue
        }
        console.warn(`å·¥å…· ${toolName} ä¸åœ¨å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­ï¼Œè·³è¿‡`)
        continue
      }
      
      const tool = this.toolOrchestrator.getTool(toolName)
      if (!tool) continue

      try {
        // è·å–å·¥å…·çš„å®Œæ•´æè¿°
        const description = await tool.prompt?.({ safeMode: false }) || await tool.description()
        
        // ç”Ÿæˆ JSON schema - ä½¿ç”¨å·¥å…·çš„å†…ç½®æ–¹æ³•
        let parameters: any
        if (tool.inputJSONSchema) {
          parameters = tool.inputJSONSchema
        } else {
          // å›é€€åˆ°ä¼ ç»Ÿè½¬æ¢æ–¹æ³•
          parameters = this.zodSchemaToJsonSchema(tool.inputSchema)
        }

        tools.push({
          type: 'function',
          function: {
            name: tool.name,
            description: `${description}\n\næƒé™çº§åˆ«: ${tool.isReadOnly() ? 'åªè¯»' : 'å¯å†™'}\nå¹¶å‘å®‰å…¨: ${tool.isConcurrencySafe() ? 'æ˜¯' : 'å¦'}`,
            parameters
          }
        })
        
        console.log(`âœ… å·¥å…· ${toolName} å·²æ·»åŠ åˆ° API è°ƒç”¨ä¸­`)
      } catch (error) {
        console.warn(`è½¬æ¢å·¥å…· ${toolName} åˆ° DeepSeek æ ¼å¼å¤±è´¥:`, error)
        
        // ä½¿ç”¨åŸºç¡€æè¿°ä½œä¸ºåå¤‡
        try {
          const basicDescription = await tool.description()
          tools.push({
            type: 'function',
            function: {
              name: tool.name,
              description: basicDescription,
              parameters: {
                type: 'object',
                properties: {},
                required: [],
                additionalProperties: true
              }
            }
          })
          console.log(`âš ï¸  å·¥å…· ${toolName} ä½¿ç”¨åŸºç¡€æ ¼å¼æ·»åŠ `)
        } catch (fallbackError) {
          console.error(`å·¥å…· ${toolName} å®Œå…¨è½¬æ¢å¤±è´¥:`, fallbackError)
        }
      }
    }

    if (tools.length > 0) {
      console.log(`ğŸ”§ å…±è½¬æ¢ ${tools.length} ä¸ªå·¥å…·ä¾› AI ä½¿ç”¨`)
    }

    return tools
  }

  /**
   * å°† Zod schema è½¬æ¢ä¸º JSON Schema
   */
  private zodSchemaToJsonSchema(zodSchema: any): any {
    // ç®€åŒ–çš„ Zod åˆ° JSON Schema è½¬æ¢
    // åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œå»ºè®®ä½¿ç”¨ zod-to-json-schema åº“
    const shape = zodSchema._def?.shape
    if (!shape) {
      return {
        type: 'object',
        properties: {},
        required: [],
        additionalProperties: false
      }
    }

    const properties: any = {}
    const required: string[] = []

    for (const [key, zodType] of Object.entries(shape)) {
      const fieldSchema = this.zodTypeToJsonSchema(zodType as any)
      properties[key] = fieldSchema
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯å¿…éœ€å­—æ®µ
      if (!(zodType as any)._def?.optional) {
        required.push(key)
      }
    }

    return {
      type: 'object',
      properties,
      required,
      additionalProperties: false
    }
  }

  /**
   * å°† Zod ç±»å‹è½¬æ¢ä¸º JSON Schema å­—æ®µ
   */
  private zodTypeToJsonSchema(zodType: any): any {
    const typeName = zodType._def.typeName
    
    switch (typeName) {
      case 'ZodString':
        return {
          type: 'string',
          description: zodType.description || ''
        }
      case 'ZodNumber':
        return {
          type: 'number', 
          description: zodType.description || ''
        }
      case 'ZodBoolean':
        return {
          type: 'boolean',
          description: zodType.description || ''
        }
      case 'ZodOptional':
        return this.zodTypeToJsonSchema(zodType._def.innerType)
      case 'ZodDefault':
        const innerSchema = this.zodTypeToJsonSchema(zodType._def.innerType)
        innerSchema.default = zodType._def.defaultValue()
        return innerSchema
      case 'ZodArray':
        return {
          type: 'array',
          items: this.zodTypeToJsonSchema(zodType._def.type),
          description: zodType.description || ''
        }
      default:
        return {
          type: 'string',
          description: zodType.description || ''
        }
    }
  }

  /**
   * å®‰å…¨çš„ JSON è§£æï¼Œå¤„ç†è½¬ä¹‰å­—ç¬¦é—®é¢˜
   */
  private safeJSONParse(jsonStr: string): any {
    try {
      return JSON.parse(jsonStr)
    } catch (error) {
      console.log(`ğŸ”§ å°è¯•ä¿®å¤ JSON æ ¼å¼...`)
      
      // å°è¯•ä¿®å¤å¸¸è§çš„ JSON è½¬ä¹‰é—®é¢˜
      let fixedJson = jsonStr
        // ä¿®å¤æ¢è¡Œç¬¦
        .replace(/\\n/g, '\\\\n')
        // ä¿®å¤åˆ¶è¡¨ç¬¦
        .replace(/\\t/g, '\\\\t')
        // ä¿®å¤å›è½¦ç¬¦
        .replace(/\\r/g, '\\\\r')
        // ä¿®å¤åæ–œæ 
        .replace(/\\\\/g, '\\\\\\\\')
        // ä¿®å¤å•ç‹¬çš„å¼•å·è½¬ä¹‰
        .replace(/\\"/g, '\\\\"')
      
      try {
        return JSON.parse(fixedJson)
      } catch (retryError) {
        // æœ€åå°è¯•ï¼šç§»é™¤é—®é¢˜å­—ç¬¦å¹¶é‡æ–°è§£æ
        try {
          const cleanJson = jsonStr
            .replace(/[\x00-\x1F\x7F]/g, '') // ç§»é™¤æ§åˆ¶å­—ç¬¦
            .replace(/\\(?!["\\/bfnrtu])/g, '\\\\') // ä¿®å¤æ— æ•ˆè½¬ä¹‰
          
          return JSON.parse(cleanJson)
        } catch (finalError) {
          throw new Error(`JSON è§£æå¤±è´¥ - åŸå§‹é”™è¯¯: ${error instanceof Error ? error.message : 'æœªçŸ¥'}, é‡è¯•é”™è¯¯: ${retryError instanceof Error ? retryError.message : 'æœªçŸ¥'}, æœ€ç»ˆé”™è¯¯: ${finalError instanceof Error ? finalError.message : 'æœªçŸ¥'}`)
        }
      }
    }
  }

  /**
   * æ ‡å‡†åŒ–å·¥å…·å‚æ•° - è§£å†³ AI æ¨¡å‹å‚æ•°å‘½åä¸ä¸€è‡´é—®é¢˜
   */
  private normalizeToolParams(toolName: string, args: any): any {
    const normalized = { ...args }
    
    switch (toolName) {
      case 'Read':
        // AI å¸¸ç”¨: path, file_path, filePath, filename
        if (args.path && !args.file_path) normalized.file_path = args.path
        if (args.filePath && !args.file_path) normalized.file_path = args.filePath  
        if (args.filename && !args.file_path) normalized.file_path = args.filename
        break
        
      case 'Write':
        if (args.path && !args.file_path) normalized.file_path = args.path
        if (args.filePath && !args.file_path) normalized.file_path = args.filePath
        if (args.text && !args.content) normalized.content = args.text
        break
        
      case 'Edit': 
        if (args.path && !args.file_path) normalized.file_path = args.path
        if (args.filePath && !args.file_path) normalized.file_path = args.filePath
        if (args.new_content && !args.new_string) normalized.new_string = args.new_content
        if (args.replacement && !args.new_string) normalized.new_string = args.replacement
        break
        
      case 'Bash':
        // AI å¸¸ç”¨: cmd, command
        if (args.cmd && !args.command) normalized.command = args.cmd
        if (args.script && !args.command) normalized.command = args.script
        break
        
      case 'Grep':
        if (args.search && !args.pattern) normalized.pattern = args.search
        if (args.query && !args.pattern) normalized.pattern = args.query
        break
        
      case 'Glob':
        if (args.search && !args.pattern) normalized.pattern = args.search
        if (args.glob && !args.pattern) normalized.pattern = args.glob
        break
    }
    
    return normalized
  }

  /**
   * æ‰§è¡Œ DeepSeek API çš„å·¥å…·è°ƒç”¨ - ä½¿ç”¨æ–°çš„å·¥å…·ç¼–æ’å™¨
   */
  private async executeDeepSeekToolCall(toolCall: any): Promise<AIToolExecutionResult> {
    const { name: toolName, arguments: argsStr } = toolCall.function
    
    // å®‰å…¨çš„ JSON è§£æ
    let args: any
    try {
      args = this.safeJSONParse(argsStr)
      // ç§»é™¤è¯¦ç»†å‚æ•°æ—¥å¿— - å¤ªå†—ä½™äº†
      // console.log(`ğŸ”§ [${toolName}] è§£æå‚æ•°:`, JSON.stringify(args, null, 2))
      
      // ğŸ”§ æ–°å¢ï¼šæ ‡å‡†åŒ–å‚æ•°ï¼Œè§£å†³ AI æ¨¡å‹å‚æ•°å‘½åä¸ä¸€è‡´é—®é¢˜
      args = this.normalizeToolParams(toolName, args)
      // console.log(`ğŸ”§ [${toolName}] æ ‡å‡†åŒ–åå‚æ•°:`, JSON.stringify(args, null, 2))
    } catch (parseError) {
      console.error(`âŒ [${toolName}] JSON è§£æå¤±è´¥ï¼ŒåŸå§‹å­—ç¬¦ä¸²:`, argsStr)
      return {
        toolName,
        callId: toolCall.id,
        result: '',
        success: false,
        error: `å·¥å…·è°ƒç”¨å‚æ•° JSON è§£æå¤±è´¥: ${parseError instanceof Error ? parseError.message : 'æœªçŸ¥é”™è¯¯'}`
      }
    }

    try {
      // åˆ›å»ºå·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡
      const toolContext: ToolUseContext = {
        messageId: `deepseek-${toolCall.id}`,
        agentId: 'deepseek-ai',
        safeMode: false,
        abortController: new AbortController(),
        readFileTimestamps: {},
        options: {
          verbose: true,
          safeMode: false,
          messageLogName: 'deepseek-ai'
        }
      }

      // è‹¥ç¼–æ’å™¨æ²¡æœ‰æ³¨å†Œè¯¥å·¥å…·ï¼Œç›´æ¥èµ°æ—§åŸŸå·¥å…·æ‰§è¡Œ
      if (!this.toolOrchestrator.getTool(toolName)) {
        const legacy = await this.executeLegacyTool(toolName, args)
        if (legacy) {
          return {
            toolName,
            callId: toolCall.id,
            result: legacy.result,
            success: legacy.success,
            error: legacy.error
          }
        }
      }

      // ä½¿ç”¨å·¥å…·ç¼–æ’å™¨æ‰§è¡Œå·¥å…·è°ƒç”¨
      const executionResult = await this.toolOrchestrator.executeTool({
        toolName,
        input: args,
        context: toolContext,
        priority: 5 // ä¸­ç­‰ä¼˜å…ˆçº§
      })

      // è½¬æ¢ä¸ºæ—§æ ¼å¼çš„ç»“æœï¼ˆå…¼å®¹æ€§ï¼‰
      if (executionResult.status === ToolExecutionStatus.COMPLETED) {
        return {
          toolName,
          callId: toolCall.id,
          result: this.formatToolResult(executionResult.result, toolName),
          success: true
        }
      } else {
        // å¦‚æœæ˜¯æœªæ‰¾åˆ°ä¹‹ç±»çš„é”™è¯¯ï¼Œé€€å›æ—§åŸŸå·¥å…·æ‰§è¡Œ
        if (executionResult.error?.message?.includes('æœªæ‰¾åˆ°') || executionResult.error?.message?.includes('not found')) {
          const legacy = await this.executeLegacyTool(toolName, args)
          if (legacy) {
            return {
              toolName,
              callId: toolCall.id,
              result: legacy.result,
              success: legacy.success,
              error: legacy.error
            }
          }
        }
        return {
          toolName,
          callId: toolCall.id,
          result: '',
          success: false,
          error: executionResult.error?.message || 'å·¥å…·æ‰§è¡Œå¤±è´¥'
        }
      }
    } catch (error) {
      return {
        toolName,
        callId: toolCall.id,
        result: '',
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      }
    }
  }

  /**
   * æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœ
   */
  private formatToolResult(result: any, toolName: string): string {
    if (typeof result === 'string') {
      return result
    }
    
    if (toolName === 'Write' && result?.success) {
      return `æ–‡ä»¶å·²æˆåŠŸå†™å…¥ ${result.filePath} (${result.bytesWritten} å­—èŠ‚)`
    }
    
    if (toolName === 'Read' && result?.content) {
      return `æ–‡ä»¶å†…å®¹å·²è¯»å–ï¼Œé•¿åº¦: ${result.content.length} å­—ç¬¦`
    }
    
    if (toolName === 'Bash' && typeof result === 'object') {
      return result.output || result.stdout || JSON.stringify(result)
    }
    
    return JSON.stringify(result)
  }

  /**
   * å¤„ç†å·¥å…·äº¤äº’ (æ—§ç‰ˆæœ¬ï¼Œå·²è¢« DeepSeek åŸç”Ÿæ”¯æŒæ›¿ä»£)
   */
  private async processToolInteractions(response: AIResponse, request: AIRequest): Promise<AIResponse> {
    let currentContent = response.content
    let iterationCount = 0
    const maxIterations = 3 // é˜²æ­¢æ— é™å¾ªç¯

    while (iterationCount < maxIterations) {
      // æ£€æµ‹å·¥å…·è°ƒç”¨
      const toolCalls = this.detectToolCalls(currentContent, request.allowedTools!)
      
      if (toolCalls.length === 0) {
        // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¤„ç†
        break
      }

      console.log(`ğŸ”§ æ£€æµ‹åˆ° ${toolCalls.length} ä¸ªå·¥å…·è°ƒç”¨`)
      
      // æ‰§è¡Œå·¥å…·è°ƒç”¨
      const toolResults: AIToolExecutionResult[] = []
      for (const toolCall of toolCalls) {
        const result = await this.executeToolCall(toolCall)
        toolResults.push(result)
        
        // æ˜¾ç¤ºå·¥å…·æ‰§è¡Œè¿‡ç¨‹ - ä½¿ç”¨ç®€æ´æ¶ˆæ¯
        if (result.success) {
          const briefMessage = this.getBriefResultMessage(result.toolName, 'success', result.result)
          console.log(briefMessage)
        } else {
          const briefMessage = this.getBriefResultMessage(result.toolName, 'error', result.error || 'æ‰§è¡Œå¤±è´¥')
          console.log(briefMessage)
        }
      }

      // å°†å·¥å…·ç»“æœé›†æˆåˆ°å“åº”ä¸­
      currentContent = this.integrateToolResults(currentContent, toolResults)
      response.hasToolInteraction = true
      
      iterationCount++
    }

    response.content = currentContent
    return response
  }

  /**
   * æ£€æµ‹å·¥å…·è°ƒç”¨
   */
  private detectToolCalls(content: string, allowedTools: string[]): ToolCall[] {
    const toolCalls: ToolCall[] = []
    
    // æ£€æµ‹æ ¼å¼ï¼šWrite("filename", "content")
    for (const toolName of allowedTools) {
      const regex = new RegExp(`${toolName}\\s*\\(\\s*"([^"]+)"(?:\\s*,\\s*"([^"]*)")?\\s*\\)`, 'gi')
      let match
      
      while ((match = regex.exec(content)) !== null) {
        const callId = `${toolName}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
        
        toolCalls.push({
          toolName,
          parameters: {
            file_path: match[1],
            content: match[2] || ''
          },
          callId
        })
      }
    }
    
    return toolCalls
  }

  /**
   * æ‰§è¡Œå·¥å…·è°ƒç”¨
   */
  private async executeToolCall(toolCall: ToolCall): Promise<AIToolExecutionResult> {
    try {
      const tool = getTool(toolCall.toolName)
      if (!tool) {
        // å…¼å®¹æ—§åŸŸå†™ä½œå·¥å…·ï¼ˆtodo_* ç­‰ï¼‰â€”â€”ç›´æ¥è°ƒç”¨å·¥å…·å®ç°
        const legacy = await this.executeLegacyTool(toolCall.toolName, toolCall.parameters)
        if (legacy) return { toolName: toolCall.toolName, callId: toolCall.callId, ...legacy }

        return {
          toolName: toolCall.toolName,
          callId: toolCall.callId,
          result: '',
          success: false,
          error: `å·¥å…· ${toolCall.toolName} ä¸å­˜åœ¨`
        }
      }

      // åˆ›å»ºå·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡
      const toolContext: ToolUseContext = {
        messageId: `ai-${toolCall.callId}`,
        agentId: 'ai-service',
        safeMode: false,
        abortController: new AbortController(),
        readFileTimestamps: {},
        options: {
          verbose: true,
          safeMode: false,
          messageLogName: 'ai-service'
        }
      }

      // æ‰§è¡Œå·¥å…· - ä½¿ç”¨ call æ–¹æ³•
      const generator = tool.call(toolCall.parameters, toolContext)
      const { value } = await generator.next()
      
      const result = value?.data || value

      return {
        toolName: toolCall.toolName,
        callId: toolCall.callId,
        result: typeof result === 'string' ? result : JSON.stringify(result),
        success: true
      }
    } catch (error) {
      return {
        toolName: toolCall.toolName,
        callId: toolCall.callId,
        result: '',
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      }
    }
  }

  /**
   * ç›´æ¥æ‰§è¡Œæ—§åŸŸå·¥å…·ï¼ˆæœªæ³¨å†Œåˆ°ç¼–æ’å™¨ï¼‰
   */
  private async executeLegacyTool(toolName: string, params: any): Promise<{ result: string; success: boolean; error?: string } | null> {
    try {
      // ç»Ÿä¸€ä¼šè¯ IDï¼Œç¡®ä¿ä¸ UI/CLI ä½¿ç”¨åŒä¸€ä¸ª Todo å­˜å‚¨
      const sessionId = process.env.WRITEFLOW_SESSION_ID
      const { TodoManager } = await import('../../tools/TodoManager.js')
      const sharedManager = new TodoManager(sessionId)

      if (toolName === 'todo_write') {
        const { TodoWriteTool } = await import('../../tools/writing/TodoWriteTool.js')
        const tool = new TodoWriteTool(sharedManager)
        const res = await tool.execute(params, { agentId: 'ai-service', abortController: new AbortController(), options: { verbose: false } })
        return { result: res.content || '', success: res.success, error: res.success ? undefined : (res as any).error }
      }
      if (toolName === 'todo_read') {
        const { TodoReadTool } = await import('../../tools/writing/TodoReadTool.js')
        const tool = new TodoReadTool(sharedManager)
        const res = await tool.execute(params, { agentId: 'ai-service', abortController: new AbortController(), options: { verbose: false } })
        return { result: res.content || '', success: res.success, error: res.success ? undefined : (res as any).error }
      }
      if (toolName === 'exit_plan_mode') {
        // ç®€åŒ–å¤„ç†ï¼šè¿”å›å›ºå®šæ¶ˆæ¯ï¼Œäº¤ç”±ä¸Šå±‚è§£æ
        return { result: 'å·²é€€å‡ºè®¡åˆ’æ¨¡å¼', success: true }
      }
      return null
    } catch (error) {
      return { result: '', success: false, error: (error as Error).message }
    }
  }

  /**
   * å°†å·¥å…·ç»“æœé›†æˆåˆ°å†…å®¹ä¸­
   */
  private integrateToolResults(content: string, results: AIToolExecutionResult[]): string {
    let updatedContent = content
    
    for (const result of results) {
      if (result.success) {
        // åœ¨å·¥å…·è°ƒç”¨ä½ç½®æ˜¾ç¤ºæ‰§è¡Œç»“æœ
        const toolCallPattern = new RegExp(`${result.toolName}\\s*\\([^)]+\\)`, 'gi')
        updatedContent = updatedContent.replace(toolCallPattern, (match) => {
          return `${match}\nâœ… [å·¥å…·æ‰§è¡Œå®Œæˆ] ${result.result}`
        })
      } else {
        // æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        const toolCallPattern = new RegExp(`${result.toolName}\\s*\\([^)]+\\)`, 'gi')
        updatedContent = updatedContent.replace(toolCallPattern, (match) => {
          return `${match}\nâŒ [å·¥å…·æ‰§è¡Œå¤±è´¥] ${result.error}`
        })
      }
    }
    
    return updatedContent
  }
}

// å…¨å±€æœåŠ¡å®ä¾‹
let globalAIService: WriteFlowAIService | null = null

/**
 * è·å–å…¨å±€ AI æœåŠ¡å®ä¾‹
 */
export function getWriteFlowAIService(): WriteFlowAIService {
  if (!globalAIService) {
    globalAIService = new WriteFlowAIService()
  }
  return globalAIService
}

/**
 * å¿«é€Ÿ AI è¯·æ±‚å‡½æ•°
 */
export async function askAI(prompt: string, options?: Partial<AIRequest>): Promise<string> {
  const service = getWriteFlowAIService()
  const response = await service.processRequest({
    prompt,
    ...options
  })
  return response.content
}
