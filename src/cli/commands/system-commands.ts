import { SlashCommand } from '../../types/command.js'
import { AgentContext } from '../../types/agent.js'

/**
 * ç³»ç»Ÿç®¡ç†å‘½ä»¤å®ç°
 */
export const systemCommands: SlashCommand[] = [
  {
    type: 'local',
    name: 'model',
    description: 'è®¾ç½®AIæ¨¡å‹',
    aliases: ['æ¨¡å‹', 'ai'],
    usage: '/model [æ¨¡å‹å]',
    examples: [
      '/model claude-3-opus-20240229',
      '/model claude-3-sonnet-20240229',
      '/model'
    ],
    
    async call(args: string, context: AgentContext): Promise<string> {
      const input = args.trim()
      
      // è·å–é»˜è®¤æ¨¡å‹çš„è¾…åŠ©å‡½æ•°
      const getDefaultModel = (provider: string): string => {
        switch (provider) {
          case 'deepseek': return 'deepseek-chat'
          case 'qwen3': return 'qwen-max'  
          case 'glm4.5': return 'glm-4.5'
          default: return 'claude-opus-4-1-20250805'
        }
      }
      
      // è·å–å½“å‰é…ç½®
      const currentProvider = process.env.API_PROVIDER || 'anthropic'
      const currentModel = process.env.AI_MODEL || getDefaultModel(currentProvider)
      
      // å®šä¹‰æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹
      const supportedModels = {
        anthropic: [
          { name: 'claude-opus-4-1-20250805', desc: 'Opus 4.1 - æœ€å¼ºæ¨ç†', default: true },
          { name: 'claude-opus-4-1-20250805-thinking', desc: 'Opus 4.1 æ€ç»´é“¾' },
          { name: 'claude-opus-4-20250514', desc: 'Opus 4 - å¼ºå¤§æ¨ç†' },
          { name: 'claude-sonnet-4-20250514', desc: 'Sonnet 4 - å¹³è¡¡æ€§èƒ½' },
          { name: 'claude-3-5-sonnet-20241022', desc: 'Sonnet 3.5 - å¿«é€Ÿå“åº”' },
          { name: 'claude-3-5-haiku-20241022', desc: 'Haiku 3.5 - æé€Ÿ' }
        ],
        deepseek: [
          { name: 'deepseek-chat', desc: 'é€šç”¨å¯¹è¯æ¨¡å‹', default: true },
          { name: 'deepseek-reasoner', desc: 'æ·±åº¦æ¨ç†æ¨¡å‹' },
          { name: 'deepseek-v3-chat', desc: 'v3 å¯¹è¯æ¨¡å‹' },
          { name: 'deepseek-v3-reasoner', desc: 'v3 æ¨ç†æ¨¡å‹' }
        ],
        qwen3: [
          { name: 'qwen-max', desc: 'æœ€å¼ºç‰ˆæœ¬', default: true },
          { name: 'qwen-plus', desc: 'é«˜æ€§ä»·æ¯”ç‰ˆæœ¬' },
          { name: 'qwen-turbo', desc: 'é€Ÿåº¦ä¼˜å…ˆç‰ˆæœ¬' }
        ],
        'glm4.5': [
          { name: 'glm-4.5', desc: 'å‡çº§ç‰ˆæœ¬', default: true },
          { name: 'glm-4', desc: 'æ ‡å‡†ç‰ˆæœ¬' },
          { name: 'glm-4-air', desc: 'è½»é‡å¿«é€Ÿç‰ˆæœ¬' },
          { name: 'glm-4-flash', desc: 'æé€Ÿå“åº”ç‰ˆæœ¬' },
          { name: 'glm-4v', desc: 'å¤šæ¨¡æ€ç‰ˆæœ¬' }
        ]
      }
      
      if (!input) {
        // æ˜¾ç¤ºå½“å‰é…ç½®å’Œæ‰€æœ‰å¯ç”¨æ¨¡å‹
        let result = `å½“å‰é…ç½®:\n  æä¾›å•†: ${currentProvider}\n  æ¨¡å‹: ${currentModel}\n\nå¯ç”¨æ¨¡å‹:\n\n`
        
        Object.entries(supportedModels).forEach(([provider, models]) => {
          const providerNames = {
            anthropic: 'Anthropic Claude',
            deepseek: 'Deepseek v3.1',
            qwen3: 'é€šä¹‰åƒé—® Qwen3',
            'glm4.5': 'æ™ºè°± GLM-4.5'
          }
          
          result += `ã€${providerNames[provider as keyof typeof providerNames]}ã€‘\n`
          models.forEach(model => {
            const defaultMark = model.default ? ' (é»˜è®¤)' : ''
            result += `  â€¢ ${model.name}${defaultMark} - ${model.desc}\n`
          })
          result += '\n'
        })
        
        result += 'ä½¿ç”¨æ–¹æ³•:\n  /model <æä¾›å•†>        - åˆ‡æ¢æä¾›å•†\n  /model <æ¨¡å‹å>       - åˆ‡æ¢å…·ä½“æ¨¡å‹'
        return result
      }
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯æä¾›å•†åˆ‡æ¢
      if (Object.keys(supportedModels).includes(input)) {
        const defaultModel = supportedModels[input as keyof typeof supportedModels]
          .find(model => model.default)?.name || supportedModels[input as keyof typeof supportedModels][0].name
        return `å·²åˆ‡æ¢åˆ°æä¾›å•†: ${input}\né»˜è®¤æ¨¡å‹: ${defaultModel}\n\nè¯·è®¾ç½®ç¯å¢ƒå˜é‡:\nexport API_PROVIDER=${input}\nexport AI_MODEL=${defaultModel}`
      }
      
      // æ£€æŸ¥å…·ä½“æ¨¡å‹å
      const allModels = Object.values(supportedModels).flat().map(m => m.name)
      if (!allModels.includes(input)) {
        return `æ— æ•ˆçš„æ¨¡å‹å: ${input}\n\nä½¿ç”¨ /model æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹`
      }
      
      // æ‰¾åˆ°æ¨¡å‹å¯¹åº”çš„æä¾›å•†
      let targetProvider = ''
      for (const [provider, models] of Object.entries(supportedModels)) {
        if (models.some(model => model.name === input)) {
          targetProvider = provider
          break
        }
      }
      
      return `å·²åˆ‡æ¢åˆ°æ¨¡å‹: ${input}\næä¾›å•†: ${targetProvider}\n\nè¯·è®¾ç½®ç¯å¢ƒå˜é‡:\nexport API_PROVIDER=${targetProvider}\nexport AI_MODEL=${input}`
    },
    
    userFacingName: () => 'model'
  },

  {
    type: 'local',
    name: 'settings',
    description: 'æ‰“å¼€è®¾ç½®ç•Œé¢',
    aliases: ['è®¾ç½®', 'config'],
    
    async call(_args: string, context: AgentContext): Promise<string> {
      const getDefaultModel = (provider: string): string => {
        switch (provider) {
          case 'deepseek': return 'deepseek-chat'
          case 'qwen3': return 'qwen-max'  
          case 'glm4.5': return 'glm-4.5'
          default: return 'claude-opus-4-1-20250805'
        }
      }
      
      const currentProvider = process.env.API_PROVIDER || 'anthropic'
      const currentModel = process.env.AI_MODEL || getDefaultModel(currentProvider)
      
      return `WriteFlow è®¾ç½®

ğŸ“ å†™ä½œè®¾ç½®:
  é»˜è®¤é£æ ¼: æŠ€æœ¯æ€§æ–‡ç« 
  ç›®æ ‡å­—æ•°: 2000
  è‡ªåŠ¨å¤§çº²: å¯ç”¨
  
ğŸ¤– AI è®¾ç½®:
  æä¾›å•†: ${currentProvider}
  æ¨¡å‹: ${currentModel}
  æ¸©åº¦: 0.7
  
ğŸ“¤ å‘å¸ƒè®¾ç½®:
  å¾®ä¿¡è‡ªåŠ¨æ ¼å¼åŒ–: å¯ç”¨
  çŸ¥ä¹æ·»åŠ å¼•ç”¨: å¯ç”¨

âš¡ æ€§èƒ½è®¾ç½®:
  æœ€å¤§å¹¶å‘å·¥å…·: ${context.configuration?.maxConcurrentTools || 5}
  å·¥å…·è¶…æ—¶: ${context.configuration?.toolTimeout || 120000}ms
  ä¸Šä¸‹æ–‡å‹ç¼©é˜ˆå€¼: ${context.configuration?.contextCompressionThreshold || 0.92}
  
ä½¿ç”¨ /model, /style ç­‰å‘½ä»¤ä¿®æ”¹å…·ä½“è®¾ç½®`
    },
    
    userFacingName: () => 'settings'
  },

  {
    type: 'local',
    name: 'status',
    description: 'æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€',
    aliases: ['çŠ¶æ€', 'stat'],
    
    async call(_args: string, context: AgentContext): Promise<string> {
      const now = new Date().toLocaleString('zh-CN')
      
      return `WriteFlow ç³»ç»ŸçŠ¶æ€ (${now})

ğŸ§  Agent çŠ¶æ€:
  ä¼šè¯ ID: ${context.sessionId}
  å½“å‰çŠ¶æ€: ${context.currentState || 'idle'}
  è®¡åˆ’æ¨¡å¼: ${context.planMode || 'default'}
  å·¥ä½œç›®å½•: ${context.workingDirectory || 'unknown'}
  
ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
  æ¶ˆæ¯å·²å¤„ç†: ${context.statistics?.messagesProcessed || 0}
  å·¥å…·è°ƒç”¨æ¬¡æ•°: ${context.statistics?.toolInvocations || 0}
  å¹³å‡å“åº”æ—¶é—´: ${context.statistics?.averageResponseTime || 0}ms
  é”™è¯¯è®¡æ•°: ${context.statistics?.errorCount || 0}
  
âš™ï¸ é…ç½®ä¿¡æ¯:
  æœ€å¤§å¹¶å‘å·¥å…·: ${context.configuration?.maxConcurrentTools || 5}
  å·¥å…·è¶…æ—¶: ${context.configuration?.toolTimeout || 120000}ms
  å®‰å…¨çº§åˆ«: ${context.configuration?.securityLevel || 'normal'}
  
ğŸ’¾ èµ„æºä½¿ç”¨:
  å†…å­˜ä½¿ç”¨: ${Math.round((process.memoryUsage().heapUsed / 1024 / 1024) * 100) / 100} MB
  Node.js ç‰ˆæœ¬: ${process.version}
  
ğŸš€ ç‰ˆæœ¬ä¿¡æ¯:
  WriteFlow: 1.0.4
  çŠ¶æ€: è¿è¡Œæ­£å¸¸`
    },
    
    userFacingName: () => 'status'
  },

  {
    type: 'local',
    name: 'clear',
    description: 'æ¸…é™¤ä¼šè¯å†å²',
    aliases: ['æ¸…é™¤', 'é‡ç½®', 'reset'],
    
    async call(_args: string, context: AgentContext): Promise<string> {
      // æ¸…ç†ä¸Šä¸‹æ–‡
      if (context.conversationHistory) {
        context.conversationHistory.length = 0
      }
      
      // é‡ç½®ç»Ÿè®¡ä¿¡æ¯
      if (context.statistics) {
        context.statistics.messagesProcessed = 0
        context.statistics.toolInvocations = 0
        context.statistics.averageResponseTime = 0
        context.statistics.errorCount = 0
        context.statistics.lastActivity = Date.now()
      }
      
      return `âœ… ä¼šè¯å†å²å·²æ¸…é™¤
      
ç³»ç»ŸçŠ¶æ€:
- å¯¹è¯å†å²: å·²é‡ç½®
- ç»Ÿè®¡ä¿¡æ¯: å·²é‡ç½®
- ä¸Šä¸‹æ–‡å‹ç¼©: å·²é‡Šæ”¾

å¯ä»¥å¼€å§‹æ–°çš„å†™ä½œä¼šè¯äº†ï¼`
    },
    
    userFacingName: () => 'clear'
  }
]