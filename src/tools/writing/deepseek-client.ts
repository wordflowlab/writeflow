import { debugLog, logWarn } from '../../utils/log.js'
import { WritingTool, ToolInput, ToolResult } from '../../types/tool.js'
import { AIWritingConfig } from '../../types/writing.js'

/**

 * Deepseek Client å·¥å…·
 * åŸºäº OpenAI å…¼å®¹åè®®çš„ Deepseek API å®¢æˆ·ç«¯
 */
export class DeepseekClientTool implements WritingTool {
  name = 'deepseek_client'
  description = 'Deepseek v3.1 API å®¢æˆ·ç«¯'
  securityLevel = 'ai-powered' as const

  constructor(private config: AIWritingConfig) {}

  async execute(input: ToolInput): Promise<ToolResult> {
    try {
      const {
        messages,
        systemPrompt,
        temperature,
        maxTokens,
        model,
        tools
      } = input as {
        messages: Array<{ role: 'user' | 'assistant' | 'system'; content: string }>
        systemPrompt?: string
        temperature?: number
        maxTokens?: number
        model?: string
        tools?: any[]
      }

      if (!messages || messages.length === 0) {
        return {
          success: false,
          error: 'ç¼ºå°‘æ¶ˆæ¯å‚æ•°'
        }
      }

      // éªŒè¯ API å¯†é’¥
      if (!this.config.anthropicApiKey) {
        return {
          success: false,
          error: 'æœªé…ç½® API å¯†é’¥'
        }
      }

      // æ„å»ºè¯·æ±‚å‚æ•°
      const requestModel = model || this.config.model
      const requestMessages = [...messages]
      
      // å¦‚æœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ ä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯
      if (systemPrompt || this.config.systemPrompt) {
        requestMessages.unshift({
          role: 'system',
          content: systemPrompt || this.config.systemPrompt || ''
        })
      }

      const requestParams: any = {
        model: requestModel,
        temperature: temperature ?? this.config.temperature,
        max_tokens: maxTokens || this.config.maxTokens,
        messages: requestMessages
      }

      // å¦‚æœæœ‰å·¥å…·å®šä¹‰ï¼Œè½¬æ¢ä¸º OpenAI æ ¼å¼
      if (tools && tools.length > 0) {
        requestParams.functions = this.convertToOpenAIFunctions(tools)
        requestParams.function_call = 'auto'
      }

      // è°ƒç”¨ API
      const response = await this.callDeepseekAPI(requestParams)

      return {
        success: true,
        content: response.content,
        metadata: {
          model: response.model,
          usage: response.usage,
          requestParams,
          responseTime: response.responseTime,
          requestId: response.id,
          rawResponse: response.rawResponse,
          hasToolCalls: response.hasToolCalls,
          thinkingContent: response.thinkingContent
        }
      }

    } catch (_error) {
      return {
        success: false,
        error: `Deepseek API è°ƒç”¨å¤±è´¥: ${(error as Error).message}`
      }
    }
  }

  /**
   * è°ƒç”¨ Deepseek API (åŸç”Ÿ HTTP åè®®)
   */
  private async callDeepseekAPI(params: any): Promise<{
    content: any
    model: string
    usage: any
    responseTime: number
    id: string
    rawResponse: any
    hasToolCalls: boolean
    thinkingContent?: string
  }> {
    const startTime = Date.now()

    try {
      // ä½¿ç”¨åŸç”Ÿ HTTP è¯·æ±‚è°ƒç”¨ DeepSeek API
      const requestBody: any = {
        model: params.model,
        messages: params.messages,
        temperature: params.temperature,
        max_tokens: params.max_tokens,
        stream: false
      }

      // DeepSeek åŸç”Ÿ function calling æ ¼å¼
      if (params.functions && params.functions.length > 0) {
        requestBody.tools = params.functions.map((func: any) => ({
          type: "function",
          function: func
        }))
        requestBody.tool_choice = "auto" // DeepSeek æ”¯æŒ "auto", "none", æˆ–å…·ä½“å·¥å…·å
        // debugLog('ğŸ”§ DeepSeek åŸç”Ÿå·¥å…·å®šä¹‰:', JSON.stringify(requestBody.tools, null, 2))
      }

      // debugLog('ğŸ” å‘é€ç»™ DeepSeek çš„æ¶ˆæ¯æ•°é‡:', params.messages.length)
      // debugLog('ğŸ” ç¬¬ä¸€æ¡æ¶ˆæ¯:', JSON.stringify(params.messages[0], null, 2))
      // debugLog('ğŸ” è¯·æ±‚ä½“:', JSON.stringify(requestBody, null, 2))

      const response = await fetch((this.config.apiBaseUrl || 'https://api.deepseek.com') + '/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.config.anthropicApiKey}`
        },
        body: JSON.stringify(requestBody)
      })

      if (!response.ok) {
        throw new Error(`DeepSeek API è¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
      }

      const completion = await response.json()

      // debugLog('ğŸ“¥ DeepSeek API å“åº”çŠ¶æ€:', completion.choices[0]?.finish_reason)
      // debugLog('ğŸ“¥ DeepSeek å“åº”å†…å®¹é•¿åº¦:', completion.choices[0]?.message?.content?.length || 0)
      // debugLog('ğŸ“¥ å®Œæ•´å“åº”:', JSON.stringify(completion, null, 2))
      
      // å¤„ç†å®Œæ•´å“åº”å†…å®¹
      const choice = completion.choices[0]
      const hasToolCalls = choice?.message?.tool_calls && choice.message.tool_calls.length > 0
      
      // if (hasToolCalls) {
      //   debugLog('ğŸ¯ DeepSeek æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨:', choice.message.tool_calls.map((tc: any) => tc.function.name).join(', '))
      // }
      
      // æå– thinking å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
      let thinkingContent: string | undefined
      
      if (choice?.message?.content) {
        const thinkingMatch = choice.message.content.match(/<thinking>([\s\S]*?)<\/thinking>/)
        if (thinkingMatch) {
          thinkingContent = thinkingMatch[1].trim()
        }
      }

      // æ„é€ ç±»ä¼¼ Anthropic çš„å“åº”æ ¼å¼
      const content = []
      
      if (choice?.message?.content) {
        content.push({
          type: 'text',
          text: choice.message.content
        })
      }
      
      // å¤„ç† DeepSeek åŸç”Ÿçš„ tool_calls æ ¼å¼
      if (hasToolCalls) {
        for (const toolCall of choice.message.tool_calls) {
          content.push({
            type: 'tool_use',
            id: toolCall.id || `func_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`,
            name: toolCall.function.name,
            input: JSON.parse(toolCall.function.arguments || '{}')
          })
        }
      }

      return {
        content,
        model: completion.model,
        usage: completion.usage || {
          prompt_tokens: 0,
          completion_tokens: 0,
          total_tokens: 0
        },
        responseTime: Date.now() - startTime,
        id: completion.id || `deepseek_${Date.now()}`,
        rawResponse: completion,
        hasToolCalls,
        thinkingContent
      }

    } catch (_error) {
      // å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿå“åº”
      // ä»…åœ¨å¼€å‘æ¨¡å¼ä¸‹è¾“å‡ºé”™è¯¯ä¿¡æ¯
      if (process.env.NODE_ENV === 'development') {
        logWarn('DeepSeek API è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿå“åº”:', _error instanceof Error ? _error.message : String(_error))
      }
      
      const mockResponse = this.generateMockResponse(params, Date.now() - startTime)

      return mockResponse
    }
  }

  /**
   * è½¬æ¢å·¥å…·å®šä¹‰ä¸º OpenAI Functions æ ¼å¼
   */
  private convertToOpenAIFunctions(tools: any[]): any[] {
    return tools.map(tool => ({
      name: tool.name,
      description: tool.description,
      parameters: tool.input_schema
    }))
  }

  /**
   * ç”Ÿæˆæ¨¡æ‹Ÿå“åº”
   */
  private generateMockResponse(params: any, responseTime: number): {
    content: any
    model: string
    usage: any
    responseTime: number
    id: string
    rawResponse: any
    hasToolCalls: boolean
    thinkingContent?: string
  } {
    const lastMessage = params.messages[params.messages.length - 1]
    const userContent = lastMessage?.content || ''
    const hasFunctions = params.functions && params.functions.length > 0
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯ Plan æ¨¡å¼ (æ›´å…¨é¢çš„æ£€æµ‹)
    const isPlanMode = params.messages.some((msg: any) => 
      msg.role === 'system' && (
        msg.content?.includes('Plan æ¨¡å¼') ||
        msg.content?.includes('PLAN MODE') ||
        msg.content?.includes('plan mode') ||
        msg.content?.includes('implementation plan')
      )
    ) || (hasFunctions && params.functions.some((func: any) => func.name === 'ExitPlanMode'))

    let content: any[]
    let hasToolCalls = false
    let thinkingContent: string | undefined

    if (isPlanMode && hasFunctions) {
      // Plan æ¨¡å¼ä¸‹ç”Ÿæˆæ›´è¯¦ç»†å’Œé’ˆå¯¹æ€§çš„å“åº”
      const userRequest = userContent.substring(0, 100) // æˆªå–ç”¨æˆ·è¯·æ±‚å‰100å­—ç¬¦ç”¨äºåˆ†æ
      
      const planContent = `## Implementation Plan

### 1. Analysis
- User requirement: ${userRequest || 'ä¼˜åŒ–æˆ–å®ç°æ–°åŠŸèƒ½'}
- Current system assessment: éœ€è¦åˆ†æç°æœ‰ä»£ç ç»“æ„
- Scope determination: ç¡®å®šä¿®æ”¹èŒƒå›´å’Œå½±å“

### 2. Implementation Steps
- **File Modifications**: 
  * ä¿®æ”¹æ ¸å¿ƒæ–‡ä»¶ä»¥å®ç°æ–°åŠŸèƒ½
  * æ›´æ–°ç›¸å…³é…ç½®å’Œç±»å‹å®šä¹‰
- **Technical Approach**:
  * é‡‡ç”¨æ¸è¿›å¼å¼€å‘æ–¹å¼
  * ä¿æŒå‘åå…¼å®¹æ€§
- **Code Changes**:
  * æ·»åŠ æ–°çš„å‡½æ•°/ç±»/æ–¹æ³•
  * é›†æˆç°æœ‰ç³»ç»Ÿç»„ä»¶

### 3. Testing & Validation
- Unit tests for new functionality
- Integration testing with existing systems
- Manual verification of user interface
- Performance impact assessment

### 4. Expected Results
- Success criteria: åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œæ— ç ´åæ€§å˜æ›´
- Output description: æ»¡è¶³ç”¨æˆ·éœ€æ±‚çš„å®Œæ•´å®ç°
- Quality assurance: ä»£ç è´¨é‡å’Œç³»ç»Ÿç¨³å®šæ€§ä¿è¯`
      
      thinkingContent = `The user has requested implementation work. I need to create a comprehensive plan that breaks down the task into manageable steps. This should include analysis of requirements, technical implementation details, testing procedures, and expected outcomes. I must then call the ExitPlanMode function with this plan.`
      
      content = [
        {
          type: 'text',
          text: `<thinking>\n${thinkingContent}\n</thinking>\n\n${planContent}`
        },
        {
          type: 'tool_use',
          id: 'func_' + Math.random().toString(36).substring(2, 11),
          name: 'ExitPlanMode',
          input: {
            plan: planContent
          }
        }
      ]
      hasToolCalls = true
    } else {
      // æ™®é€šæ¨¡å¼å“åº” - é¿å…æåŠå…·ä½“æ¨¡å‹åç§°ä»¥ä¿æŒä¸€è‡´æ€§
      let textResponse = ''
      if (userContent.includes('å¤§çº²')) {
        textResponse = 'åŸºäºæ‚¨çš„è¯·æ±‚ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†è¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚ç»“æ„æ¸…æ™°ï¼Œæ¶µç›–äº†ä¸»é¢˜çš„æ ¸å¿ƒè¦ç‚¹ã€‚'
      } else if (userContent.includes('æ”¹å†™')) {
        textResponse = 'æˆ‘å·²ç»æŒ‰ç…§æ‚¨æŒ‡å®šçš„é£æ ¼å¯¹å†…å®¹è¿›è¡Œäº†æ”¹å†™ã€‚'
      } else {
        textResponse = 'æˆ‘ç†è§£æ‚¨çš„è¯·æ±‚ï¼Œæ­£åœ¨ä¸ºæ‚¨å¤„ç†ã€‚è¯·ç¨å€™...'
      }
      
      content = [{
        type: 'text',
        text: textResponse
      }]
    }

    return {
      content,
      model: params.model,
      usage: {
        prompt_tokens: 150,
        completion_tokens: 300,
        total_tokens: 450
      },
      responseTime,
      id: `deepseek_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`,
      rawResponse: { content },
      hasToolCalls,
      thinkingContent
    }
  }

  /**
   * æ£€æŸ¥ API é…ç½®
   */
  async validateConfig(): Promise<{ valid: boolean; error?: string }> {
    if (!this.config.anthropicApiKey) {
      return { valid: false, error: 'ç¼ºå°‘ API å¯†é’¥' }
    }

    if (!this.config.model) {
      return { valid: false, error: 'ç¼ºå°‘æ¨¡å‹é…ç½®' }
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„ Deepseek æ¨¡å‹
    const supportedModels = this.getSupportedModels()
    if (!supportedModels.includes(this.config.model)) {
      return { valid: false, error: `ä¸æ”¯æŒçš„æ¨¡å‹: ${this.config.model}` }
    }

    return { valid: true }
  }

  /**
   * è·å–æ”¯æŒçš„ Deepseek æ¨¡å‹åˆ—è¡¨
   */
  getSupportedModels(): string[] {
    return [
      // Deepseek v3.1 ç³»åˆ—
      'deepseek-chat',
      'deepseek-reasoner',
      
      // å…¼å®¹æ€§åˆ«å
      'deepseek-v3-chat',
      'deepseek-v3-reasoner'
    ]
  }

  async validateInput(input: ToolInput): Promise<boolean> {
    const { messages } = input as { messages?: any[] }
    return Boolean(messages && Array.isArray(messages) && messages.length > 0)
  }

  /**
   * è·å–æ¨¡å‹ä¿¡æ¯
   */
  getModelInfo(model: string): {
    name: string
    contextWindow: number
    description: string
    features: string[]
  } {
    switch (model) {
      case 'deepseek-chat':
      case 'deepseek-v3-chat':
        return {
          name: 'Deepseek Chat v3.1',
          contextWindow: 128000,
          description: 'é€šç”¨å¯¹è¯æ¨¡å‹ï¼Œé€‚åˆå„ç±»æ–‡æœ¬ç”Ÿæˆä»»åŠ¡',
          features: ['å¿«é€Ÿå“åº”', 'é«˜è´¨é‡ç”Ÿæˆ', 'å¤šè¯­è¨€æ”¯æŒ', 'ä»£ç ç”Ÿæˆ']
        }
      
      case 'deepseek-reasoner':
      case 'deepseek-v3-reasoner':
        return {
          name: 'Deepseek Reasoner v3.1',
          contextWindow: 128000,
          description: 'æ¨ç†ä¸“ç”¨æ¨¡å‹ï¼Œæ“…é•¿å¤æ‚é€»è¾‘æ¨ç†å’Œé—®é¢˜è§£å†³',
          features: ['æ·±åº¦æ¨ç†', 'é€»è¾‘åˆ†æ', 'æ•°å­¦è®¡ç®—', 'å¤æ‚é—®é¢˜è§£å†³']
        }
      
      default:
        return {
          name: 'Unknown Model',
          contextWindow: 4096,
          description: 'æœªçŸ¥æ¨¡å‹',
          features: []
        }
    }
  }

  /**
   * ä¼°ç®—tokenä½¿ç”¨é‡
   */
  estimateTokens(text: string): number {
    // ç®€å•ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦ * 1.5ï¼Œè‹±æ–‡å•è¯ * 1.3
    const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length
    const englishWords = (text.match(/[a-zA-Z]+/g) || []).length
    const otherChars = text.length - chineseChars - englishWords
    
    return Math.ceil(chineseChars * 1.5 + englishWords * 1.3 + otherChars * 0.5)
  }
}